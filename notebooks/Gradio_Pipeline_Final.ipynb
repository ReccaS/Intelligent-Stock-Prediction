{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_pipeline(user_input):\n",
    "    # notebooks/Project_3a.ipynb\n",
    "\n",
    "    # Import system references\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    # Ensure project_root is in the system path\n",
    "    current_dir = os.getcwd()\n",
    "    project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.append(project_root)\n",
    "        \n",
    "    #print(\"Project root added to sys.path:\", project_root in sys.path)\n",
    "    #print(sys.path)\n",
    "\n",
    "    #setup Logging\n",
    "    import logging\n",
    "\n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Configure logging\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    #setup Logging\n",
    "    import logging\n",
    "\n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Configure logging\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "    # Import necessary libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    from datetime import datetime\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # Import the fetch_stock_data function\n",
    "    from scripts import fetch_stock_data, transform_stock_data_to_delta, transform_with_history\n",
    "    from scripts import prepare_data_for_training, create_time_series_windows, lstm_model, prepare_sliding_window_data\n",
    "\n",
    "    # Ask the user for a ticker symbol\n",
    "    ticker = user_input\n",
    "\n",
    "    # Define start and end dates\n",
    "    start_date = '2021-01-01'\n",
    "\n",
    "    # If end_date is not provided, you can set it to today's date\n",
    "    end_date = datetime.today().strftime('%Y-%m-%d')  # Default to today's date if not specified\n",
    "\n",
    "    # Print the ticker and date range to confirm\n",
    "    print(f\"Fetching data for {ticker} from {start_date} to {end_date}\")\n",
    "\n",
    "    # Fetch stock data\n",
    "    stock_data_df = fetch_stock_data(ticker, start_date, end_date)\n",
    "    #stock_data_df = fetch_stock_data(ticker, start_date)\n",
    "\n",
    "    # Check if data is fetched successfully\n",
    "    if not stock_data_df.empty:\n",
    "        # Display the first few rows\n",
    "        display(stock_data_df.head())\n",
    "    else:\n",
    "        print(\"No data to display.\")\n",
    "\n",
    "\n",
    "    # Transform Stock Data to Deltas\n",
    "    columns_to_exclude = ['Adj Close']  # Drop 'Adj Close'\n",
    "    columns_to_keep = []  # Keep 'Volume' but exclude from delta calculation\n",
    "    columns_to_calculate = ['Open', 'High', 'Low', 'Close', 'Volume']  # Calculate deltas for 'Open' and 'Close'\n",
    "\n",
    "    transformed_data_df = transform_stock_data_to_delta(\n",
    "        stock_data_df, \n",
    "        columns_to_exclude=columns_to_exclude, \n",
    "        columns_to_calculate=columns_to_calculate, \n",
    "        columns_to_keep=columns_to_keep\n",
    "    )\n",
    "\n",
    "    #transformed_data_df = transform_stock_data_to_delta(stock_data_df)\n",
    "    #transformed_data_df = transform_stock_data_to_delta(stock_data_df, exclude=['Volume'])\n",
    "\n",
    "    # Display Transformed Data\n",
    "    if not transformed_data_df.empty:\n",
    "        display(transformed_data_df.head())\n",
    "    else:\n",
    "        print(\"No transformed data to display.\")\n",
    "\n",
    "    # Prepare the data by removing non-delta columns\n",
    "    delta_only_df = prepare_sliding_window_data(transformed_data_df)\n",
    "\n",
    "    # Display the first few rows of the resulting DataFrame\n",
    "    display(delta_only_df.head())\n",
    "\n",
    "    # Define parameters\n",
    "    n_timesteps = 100  # Number of timesteps (sequence length)\n",
    "\n",
    "    # Step 1: Create the time series windows (X and y)\n",
    "    X, y = create_time_series_windows(delta_only_df, 'Close_delta', n_timesteps)\n",
    "\n",
    "    # Display the first few occurrences of the X and y arrays\n",
    "    print(\"First 5 entries of X:\\n\", X[:5])  # Display first 5 rows\n",
    "    print(\"First 5 entries of y:\\n\", y[:5])  # Display first 5 target values\n",
    "\n",
    "    # Step 2: Split the data into training and testing sets (80/20 split)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # Display the shapes of the training and testing sets\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "    # Initialize the scaler for X and y values\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "\n",
    "    # Reshape X data to 2D for scaling, keeping the last dimension as features\n",
    "    n_samples_train = X_train.shape[0]\n",
    "    n_samples_test = X_test.shape[0]\n",
    "\n",
    "    X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])  # Reshape to 2D: [samples * timesteps, features]\n",
    "    X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "    # Apply scaling to X features (fit on X_train, transform both X_train and X_test)\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train_reshaped).reshape(n_samples_train, X_train.shape[1], X_train.shape[2])\n",
    "    X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(n_samples_test, X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "    # Reshape y values to 2D (required by MinMaxScaler)\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    # Apply scaling to y values\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "\n",
    "    # Define parameters\n",
    "    #n_timesteps = 25\n",
    "    n_features = X_train_scaled.shape[2]\n",
    "\n",
    "    # Define the number of layers and units per layer\n",
    "    num_layers = 3\n",
    "    units_per_layer = [50, 100, 50]  # 3 layers with 50, 100, and 50 units, respectively\n",
    "\n",
    "    # Call the LSTM model\n",
    "    y_pred_scaled, model = lstm_model(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, n_timesteps, n_features, num_layers, units_per_layer, \n",
    "                            learning_rate=0.00001, epochs=70, batch_size=28)\n",
    "    # Output the predictions\n",
    "    #print(\"Predictions from LSTM model:\", y_pred_scaled)\n",
    "\n",
    "    # Step 1: Inverse transform the predicted and actual y values to the original scale\n",
    "    y_pred_original = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_test_original = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "    # Display the first few occurrences of prediction and test scaled and unscaled arrays\n",
    "    print(\"First 5 entries of y_pred_scaled\", y_pred_scaled[:5])  # Display first 5 rows\n",
    "    print(\"First 5 entries of y_pred_original\", y_pred_original[:5])  # Display first 5 rows\n",
    "    print(\"First 5 entries of y_test_scaled\", y_test_scaled[:5])  # Display first 5 target values\n",
    "    print(\"First 5 entries of y_test_original\", y_test_original[:5])  # Display first 5 target values\n",
    "\n",
    "    # Mean Squared Error\n",
    "    mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "    # Root Mean Squared Error\n",
    "    rmse = np.sqrt(mse)\n",
    "    # Mean Absolute Error\n",
    "    mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "    # R-squared\n",
    "    r2 = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "    print(f\"R-squared (R²): {r2:.6f}\")\n",
    "\n",
    "\n",
    "    # Create a DataFrame to compare actual and predicted values\n",
    "    comparison_df = pd.DataFrame({'Actual': y_test_original.flatten(), 'Predicted': y_pred_original.flatten()})\n",
    "    # Calculate the difference (error)\n",
    "    comparison_df['Difference'] = comparison_df['Actual'] - comparison_df['Predicted']\n",
    "    #print(comparison_df.head(25))\n",
    "\n",
    "\n",
    "    # Get the sign of the actual and predicted values\n",
    "    actual_sign = np.sign(comparison_df['Actual'])\n",
    "    predicted_sign = np.sign(comparison_df['Predicted'])\n",
    "    #print(actual_sign.head(25))\n",
    "    #print(predicted_sign.head(25))\n",
    "    # Check where the signs match\n",
    "    sign_matches = actual_sign == predicted_sign\n",
    "    print(sign_matches.head(100))\n",
    "\n",
    "    # Calculate the percentage of sign matches\n",
    "    percentage_match = sign_matches.mean() * 100\n",
    "\n",
    "    print(f\"Percentage of Sign Matches: {percentage_match :.2f}%\")\n",
    "\n",
    "\n",
    "    # Get the prediction for tomorrow's Close_delta\n",
    "\n",
    "    \"\"\"\n",
    "    Predict the next Close_delta based on the most recent n_timesteps of data.\n",
    "        \n",
    "    Using:\n",
    "    - model: The trained LSTM model.\n",
    "    - delta_only_df (pd.DataFrame): The DataFrame containing all historical data, including the latest Close_delta.\n",
    "    - n_timesteps (int): The number of timesteps (sequence length) used in the model.\n",
    "    - scaler_X: The scaler used to scale the features (X).\n",
    "    - scaler_y: The scaler used to scale the target (y).\n",
    "\n",
    "    Returns:\n",
    "    - float: The predicted Close_delta for the next day.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract the last n_timesteps rows from the data (to be used as input for prediction)\n",
    "    last_window = delta_only_df[-n_timesteps:].values.reshape(1, n_timesteps, delta_only_df.shape[1])\n",
    "\n",
    "    # Step 2: Scale the input features\n",
    "    last_window_scaled = scaler_X.transform(last_window.reshape(-1, last_window.shape[-1])).reshape(1, n_timesteps, -1)\n",
    "\n",
    "    # Step 3: Use the model to predict the next Close_delta (scaled)\n",
    "    predicted_close_delta_scaled = model.predict(last_window_scaled)\n",
    "\n",
    "    # Step 4: Inverse transform the prediction to get the original scale of Close_delta\n",
    "    predicted_close_delta = scaler_y.inverse_transform(predicted_close_delta_scaled)\n",
    "\n",
    "    predicted_close_delta = predicted_close_delta[0][0]  # Return the predicted value\n",
    "\n",
    "    # Decision logic: Buy if positive, Sell if negative\n",
    "    if predicted_close_delta > 0:\n",
    "        print(f\"Predicted Close increase for {ticker} tomorrow is {(predicted_close_delta * 100):.2f}%. Suggestion: BUY with {percentage_match :.2f}% confidence\")\n",
    "    else:\n",
    "        print(f\"Predicted Close decrease for {ticker} tomorrow is {(predicted_close_delta * 100):.2f}%. Suggestion: SELL with {percentage_match :.2f}% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 20:40:47,406 - INFO - NumExpr defaulting to 8 threads.\n",
      "2024-10-28 20:40:57,664 - INFO - End date provided: 2024-10-28\n",
      "2024-10-28 20:40:57,665 - INFO - Fetching data for ticker: AAPL from 2021-01-01 to 2024-10-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL from 2021-01-01 to 2024-10-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 20:40:59,053 - INFO - Resetting index to make 'Date' a column.\n",
      "2024-10-28 20:40:59,055 - INFO - Flattening multi-level column names (removing ticker symbol).\n",
      "2024-10-28 20:40:59,055 - INFO - Successfully fetched and simplified data for ticker 'AAPL'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04 00:00:00+00:00</td>\n",
       "      <td>126.683449</td>\n",
       "      <td>129.410004</td>\n",
       "      <td>133.610001</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>133.520004</td>\n",
       "      <td>143301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05 00:00:00+00:00</td>\n",
       "      <td>128.249725</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>128.429993</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>97664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 00:00:00+00:00</td>\n",
       "      <td>123.932663</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>127.720001</td>\n",
       "      <td>155088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07 00:00:00+00:00</td>\n",
       "      <td>128.161606</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>131.630005</td>\n",
       "      <td>127.860001</td>\n",
       "      <td>128.360001</td>\n",
       "      <td>109578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08 00:00:00+00:00</td>\n",
       "      <td>129.267838</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.429993</td>\n",
       "      <td>105158200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Date   Adj Close       Close        High  \\\n",
       "0     2021-01-04 00:00:00+00:00  126.683449  129.410004  133.610001   \n",
       "1     2021-01-05 00:00:00+00:00  128.249725  131.009995  131.740005   \n",
       "2     2021-01-06 00:00:00+00:00  123.932663  126.599998  131.050003   \n",
       "3     2021-01-07 00:00:00+00:00  128.161606  130.919998  131.630005   \n",
       "4     2021-01-08 00:00:00+00:00  129.267838  132.050003  132.630005   \n",
       "\n",
       "Price         Low        Open     Volume  \n",
       "0      126.760002  133.520004  143301900  \n",
       "1      128.429993  128.889999   97664900  \n",
       "2      126.379997  127.720001  155088000  \n",
       "3      127.860001  128.360001  109578200  \n",
       "4      130.229996  132.429993  105158200  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 20:40:59,070 - INFO - Starting transformation of stock data to deltas.\n",
      "2024-10-28 20:40:59,071 - INFO - Dropping columns: ['Adj Close']\n",
      "2024-10-28 20:40:59,074 - INFO - Calculating deltas for specified columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "2024-10-28 20:40:59,075 - INFO - Transforming column: Open\n",
      "2024-10-28 20:40:59,078 - INFO - Transforming column: High\n",
      "2024-10-28 20:40:59,078 - INFO - Transforming column: Low\n",
      "2024-10-28 20:40:59,088 - INFO - Transforming column: Close\n",
      "2024-10-28 20:40:59,093 - INFO - Transforming column: Volume\n",
      "2024-10-28 20:40:59,095 - INFO - Dropping the first row with NaN values after delta calculation.\n",
      "2024-10-28 20:40:59,100 - INFO - Successfully transformed stock data to deltas.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open_delta</th>\n",
       "      <th>High_delta</th>\n",
       "      <th>Low_delta</th>\n",
       "      <th>Close_delta</th>\n",
       "      <th>Volume_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05 00:00:00+00:00</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>128.429993</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>97664900</td>\n",
       "      <td>-0.0347</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>-0.3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 00:00:00+00:00</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>127.720001</td>\n",
       "      <td>155088000</td>\n",
       "      <td>-0.0091</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>-0.0160</td>\n",
       "      <td>-0.0337</td>\n",
       "      <td>0.5880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07 00:00:00+00:00</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>131.630005</td>\n",
       "      <td>127.860001</td>\n",
       "      <td>128.360001</td>\n",
       "      <td>109578200</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>-0.2934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08 00:00:00+00:00</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.429993</td>\n",
       "      <td>105158200</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>-0.0403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-11 00:00:00+00:00</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>130.169998</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>129.190002</td>\n",
       "      <td>100384500</td>\n",
       "      <td>-0.0245</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>-0.0133</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>-0.0454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Date       Close        High         Low  \\\n",
       "1     2021-01-05 00:00:00+00:00  131.009995  131.740005  128.429993   \n",
       "2     2021-01-06 00:00:00+00:00  126.599998  131.050003  126.379997   \n",
       "3     2021-01-07 00:00:00+00:00  130.919998  131.630005  127.860001   \n",
       "4     2021-01-08 00:00:00+00:00  132.050003  132.630005  130.229996   \n",
       "5     2021-01-11 00:00:00+00:00  128.979996  130.169998  128.500000   \n",
       "\n",
       "Price        Open     Volume  Open_delta  High_delta  Low_delta  Close_delta  \\\n",
       "1      128.889999   97664900     -0.0347     -0.0140     0.0132       0.0124   \n",
       "2      127.720001  155088000     -0.0091     -0.0052    -0.0160      -0.0337   \n",
       "3      128.360001  109578200      0.0050      0.0044     0.0117       0.0341   \n",
       "4      132.429993  105158200      0.0317      0.0076     0.0185       0.0086   \n",
       "5      129.190002  100384500     -0.0245     -0.0185    -0.0133      -0.0232   \n",
       "\n",
       "Price  Volume_delta  \n",
       "1           -0.3185  \n",
       "2            0.5880  \n",
       "3           -0.2934  \n",
       "4           -0.0403  \n",
       "5           -0.0454  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Open_delta</th>\n",
       "      <th>High_delta</th>\n",
       "      <th>Low_delta</th>\n",
       "      <th>Close_delta</th>\n",
       "      <th>Volume_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0347</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>-0.3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0091</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>-0.0160</td>\n",
       "      <td>-0.0337</td>\n",
       "      <td>0.5880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>-0.2934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>-0.0403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.0245</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>-0.0133</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>-0.0454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price  Open_delta  High_delta  Low_delta  Close_delta  Volume_delta\n",
       "1         -0.0347     -0.0140     0.0132       0.0124       -0.3185\n",
       "2         -0.0091     -0.0052    -0.0160      -0.0337        0.5880\n",
       "3          0.0050      0.0044     0.0117       0.0341       -0.2934\n",
       "4          0.0317      0.0076     0.0185       0.0086       -0.0403\n",
       "5         -0.0245     -0.0185    -0.0133      -0.0232       -0.0454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of X:\n",
      " [[[-3.470e-02 -1.400e-02  1.320e-02  1.240e-02 -3.185e-01]\n",
      "  [-9.100e-03 -5.200e-03 -1.600e-02 -3.370e-02  5.880e-01]\n",
      "  [ 5.000e-03  4.400e-03  1.170e-02  3.410e-02 -2.934e-01]\n",
      "  ...\n",
      "  [ 1.440e-02  3.000e-03  3.000e-03 -1.600e-03  1.413e-01]\n",
      "  [-6.700e-03 -7.200e-03  8.000e-04 -4.000e-04 -2.143e-01]\n",
      "  [-4.100e-03  2.000e-03 -1.060e-02 -1.240e-02  6.725e-01]]\n",
      "\n",
      " [[-9.100e-03 -5.200e-03 -1.600e-02 -3.370e-02  5.880e-01]\n",
      "  [ 5.000e-03  4.400e-03  1.170e-02  3.410e-02 -2.934e-01]\n",
      "  [ 3.170e-02  7.600e-03  1.850e-02  8.600e-03 -4.030e-02]\n",
      "  ...\n",
      "  [-6.700e-03 -7.200e-03  8.000e-04 -4.000e-04 -2.143e-01]\n",
      "  [-4.100e-03  2.000e-03 -1.060e-02 -1.240e-02  6.725e-01]\n",
      "  [-6.900e-03 -1.440e-02 -4.200e-03 -5.300e-03 -2.464e-01]]\n",
      "\n",
      " [[ 5.000e-03  4.400e-03  1.170e-02  3.410e-02 -2.934e-01]\n",
      "  [ 3.170e-02  7.600e-03  1.850e-02  8.600e-03 -4.030e-02]\n",
      "  [-2.450e-02 -1.850e-02 -1.330e-02 -2.320e-02 -4.540e-02]\n",
      "  ...\n",
      "  [-4.100e-03  2.000e-03 -1.060e-02 -1.240e-02  6.725e-01]\n",
      "  [-6.900e-03 -1.440e-02 -4.200e-03 -5.300e-03 -2.464e-01]\n",
      "  [-3.900e-03 -3.600e-03 -4.900e-03 -2.600e-03 -5.150e-02]]\n",
      "\n",
      " [[ 3.170e-02  7.600e-03  1.850e-02  8.600e-03 -4.030e-02]\n",
      "  [-2.450e-02 -1.850e-02 -1.330e-02 -2.320e-02 -4.540e-02]\n",
      "  [-5.300e-03 -3.700e-03 -1.280e-02 -1.400e-03 -8.400e-02]\n",
      "  ...\n",
      "  [-6.900e-03 -1.440e-02 -4.200e-03 -5.300e-03 -2.464e-01]\n",
      "  [-3.900e-03 -3.600e-03 -4.900e-03 -2.600e-03 -5.150e-02]\n",
      "  [-6.400e-03 -9.000e-04  9.000e-04  6.300e-03 -1.236e-01]]\n",
      "\n",
      " [[-2.450e-02 -1.850e-02 -1.330e-02 -2.320e-02 -4.540e-02]\n",
      "  [-5.300e-03 -3.700e-03 -1.280e-02 -1.400e-03 -8.400e-02]\n",
      "  [ 2.000e-03  1.360e-02  1.280e-02  1.620e-02 -3.600e-02]\n",
      "  ...\n",
      "  [-3.900e-03 -3.600e-03 -4.900e-03 -2.600e-03 -5.150e-02]\n",
      "  [-6.400e-03 -9.000e-04  9.000e-04  6.300e-03 -1.236e-01]\n",
      "  [ 3.200e-03 -3.100e-03 -7.400e-03 -1.220e-02  2.859e-01]]]\n",
      "First 5 entries of y:\n",
      " [-0.0053 -0.0026  0.0063 -0.0122  0.019 ]\n",
      "X_train shape: (687, 100, 5)\n",
      "X_test shape: (172, 100, 5)\n",
      "y_train shape: (687,)\n",
      "y_test shape: (172,)\n",
      "Epoch 1/70\n",
      "25/25 - 6s - 238ms/step - loss: 0.1674 - val_loss: 0.1611\n",
      "Epoch 2/70\n",
      "25/25 - 2s - 75ms/step - loss: 0.1607 - val_loss: 0.1544\n",
      "Epoch 3/70\n",
      "25/25 - 2s - 90ms/step - loss: 0.1534 - val_loss: 0.1466\n",
      "Epoch 4/70\n",
      "25/25 - 2s - 76ms/step - loss: 0.1459 - val_loss: 0.1392\n",
      "Epoch 5/70\n",
      "25/25 - 2s - 90ms/step - loss: 0.1385 - val_loss: 0.1316\n",
      "Epoch 6/70\n",
      "25/25 - 2s - 86ms/step - loss: 0.1308 - val_loss: 0.1239\n",
      "Epoch 7/70\n",
      "25/25 - 3s - 107ms/step - loss: 0.1231 - val_loss: 0.1161\n",
      "Epoch 8/70\n",
      "25/25 - 6s - 233ms/step - loss: 0.1154 - val_loss: 0.1085\n",
      "Epoch 9/70\n",
      "25/25 - 5s - 219ms/step - loss: 0.1077 - val_loss: 0.1006\n",
      "Epoch 10/70\n",
      "25/25 - 2s - 93ms/step - loss: 0.0997 - val_loss: 0.0924\n",
      "Epoch 11/70\n",
      "25/25 - 2s - 91ms/step - loss: 0.0913 - val_loss: 0.0838\n",
      "Epoch 12/70\n",
      "25/25 - 3s - 101ms/step - loss: 0.0825 - val_loss: 0.0747\n",
      "Epoch 13/70\n",
      "25/25 - 3s - 105ms/step - loss: 0.0732 - val_loss: 0.0652\n",
      "Epoch 14/70\n",
      "25/25 - 3s - 102ms/step - loss: 0.0635 - val_loss: 0.0551\n",
      "Epoch 15/70\n",
      "25/25 - 3s - 111ms/step - loss: 0.0531 - val_loss: 0.0443\n",
      "Epoch 16/70\n",
      "25/25 - 3s - 109ms/step - loss: 0.0423 - val_loss: 0.0337\n",
      "Epoch 17/70\n",
      "25/25 - 3s - 115ms/step - loss: 0.0321 - val_loss: 0.0240\n",
      "Epoch 18/70\n",
      "25/25 - 3s - 121ms/step - loss: 0.0232 - val_loss: 0.0163\n",
      "Epoch 19/70\n",
      "25/25 - 3s - 115ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 20/70\n",
      "25/25 - 3s - 115ms/step - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 21/70\n",
      "25/25 - 3s - 111ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 22/70\n",
      "25/25 - 4s - 146ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 23/70\n",
      "25/25 - 3s - 137ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 24/70\n",
      "25/25 - 4s - 146ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 25/70\n",
      "25/25 - 3s - 124ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 26/70\n",
      "25/25 - 3s - 131ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 27/70\n",
      "25/25 - 4s - 147ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 28/70\n",
      "25/25 - 4s - 160ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 29/70\n",
      "25/25 - 5s - 195ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 30/70\n",
      "25/25 - 5s - 206ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 31/70\n",
      "25/25 - 3s - 137ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 32/70\n",
      "25/25 - 4s - 168ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 33/70\n",
      "25/25 - 3s - 104ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 34/70\n",
      "25/25 - 2s - 97ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 35/70\n",
      "25/25 - 3s - 127ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 36/70\n",
      "25/25 - 4s - 152ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 37/70\n",
      "25/25 - 5s - 197ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 38/70\n",
      "25/25 - 4s - 145ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 39/70\n",
      "25/25 - 4s - 147ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 40/70\n",
      "25/25 - 4s - 156ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 41/70\n",
      "25/25 - 2s - 79ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 42/70\n",
      "25/25 - 2s - 80ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 43/70\n",
      "25/25 - 2s - 79ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 44/70\n",
      "25/25 - 2s - 85ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 45/70\n",
      "25/25 - 2s - 82ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 46/70\n",
      "25/25 - 3s - 106ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 47/70\n",
      "25/25 - 4s - 142ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 48/70\n",
      "25/25 - 3s - 136ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 49/70\n",
      "25/25 - 5s - 219ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 50/70\n",
      "25/25 - 4s - 147ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 51/70\n",
      "25/25 - 2s - 76ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 52/70\n",
      "25/25 - 2s - 75ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 53/70\n",
      "25/25 - 2s - 94ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 54/70\n",
      "25/25 - 2s - 98ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 55/70\n",
      "25/25 - 2s - 99ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 56/70\n",
      "25/25 - 3s - 105ms/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 57/70\n",
      "25/25 - 3s - 101ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 58/70\n",
      "25/25 - 2s - 97ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 59/70\n",
      "25/25 - 3s - 104ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 60/70\n",
      "25/25 - 3s - 107ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 61/70\n",
      "25/25 - 3s - 108ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 62/70\n",
      "25/25 - 2s - 95ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 63/70\n",
      "25/25 - 3s - 125ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 64/70\n",
      "25/25 - 3s - 119ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 65/70\n",
      "25/25 - 3s - 120ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 66/70\n",
      "25/25 - 7s - 296ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 67/70\n",
      "25/25 - 4s - 177ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 68/70\n",
      "25/25 - 4s - 140ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 69/70\n",
      "25/25 - 5s - 188ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 70/70\n",
      "25/25 - 3s - 133ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step\n",
      "First 5 entries of y_pred_scaled [[0.3819617 ]\n",
      " [0.39173567]\n",
      " [0.4022427 ]\n",
      " [0.3881513 ]\n",
      " [0.40120047]]\n",
      "First 5 entries of y_pred_original [[-0.00228426]\n",
      " [-0.00084064]\n",
      " [ 0.00071125]\n",
      " [-0.00137005]\n",
      " [ 0.00055731]]\n",
      "First 5 entries of y_test_scaled [[0.35003385]\n",
      " [0.41435342]\n",
      " [0.50914015]\n",
      " [0.422478  ]\n",
      " [0.72647258]]\n",
      "First 5 entries of y_test_original [[-0.007 ]\n",
      " [ 0.0025]\n",
      " [ 0.0165]\n",
      " [ 0.0037]\n",
      " [ 0.0486]]\n",
      "Mean Squared Error (MSE): 0.000239\n",
      "Root Mean Squared Error (RMSE): 0.015444\n",
      "Mean Absolute Error (MAE): 0.011668\n",
      "R-squared (R²): -0.000054\n",
      "0      True\n",
      "1     False\n",
      "2      True\n",
      "3     False\n",
      "4      True\n",
      "      ...  \n",
      "95    False\n",
      "96     True\n",
      "97    False\n",
      "98    False\n",
      "99     True\n",
      "Length: 100, dtype: bool\n",
      "Percentage of Sign Matches: 53.49%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted Close increase for AAPL tomorrow is 0.16%. Suggestion: BUY with 53.49% confidence\n"
     ]
    }
   ],
   "source": [
    "stock_pipeline('AAPL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment Analysis Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import yfinance as yf \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7aa448e0b14dceb45425569de9b859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ryanw\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.distilbert.modeling_tf_distilbert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\tf_keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\tf_keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\tf_keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\tf_keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the TF-Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\tf_keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\tf_keras\\src\\applications\\convnext.py:26\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\__init__.py:85\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_data_flow_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_stitch \u001b[38;5;66;03m# line: 827\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_experimental_dataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_pinned \u001b[38;5;66;03m# line: 725\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_linalg_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m matrix_square_root \u001b[38;5;66;03m# line: 2108\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'check_pinned' from 'tensorflow.python.ops.gen_experimental_dataset_ops' (c:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_experimental_dataset_ops.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     TFBaseModelOutput,\n\u001b[0;32m     30\u001b[0m     TFMaskedLMOutput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     TFTokenClassifierOutput,\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the sentiment analysis pipeline from Hugging Face\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased-finetuned-sst-2-english\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m sentiment_analysis \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m,model\u001b[38;5;241m=\u001b[39mmodel_name)\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:926\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    925\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 926\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    927\u001b[0m         model,\n\u001b[0;32m    928\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    929\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    930\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    931\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    932\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    934\u001b[0m     )\n\u001b[0;32m    936\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    937\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\pipelines\\base.py:264\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m look_tf:\n\u001b[1;32m--> 264\u001b[0m     _class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchitecture\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1767\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   1769\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\ryanw\\anaconda3\\envs\\RyanDev2\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.distilbert.modeling_tf_distilbert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "# Initialize the sentiment analysis pipeline from Hugging Face\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch recent stock-related news using yfinance\n",
    "def fetch_stock_news(stock_symbol, num_articles=5):\n",
    "    stock = yf.Ticker(stock_symbol)\n",
    "    news = stock.news  # Get stock news\n",
    "\n",
    "    if not news:\n",
    "        return []  # Return an empty list if no news is available\n",
    "\n",
    "    #Change num_articles to int for Gradio use\n",
    "\n",
    "    num_articles = int(num_articles)\n",
    "    # Extract top `num_articles` news articles\n",
    "    news_headlines = [article['title'] for article in news[:num_articles]]\n",
    "    return news_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis on stock news headlines\n",
    "def analyze_sentiment_on_news(stock_symbol, num_articles):\n",
    "    # Fetch stock news\n",
    "    headlines = fetch_stock_news(stock_symbol, num_articles)\n",
    "\n",
    "    # Check if headlines are available\n",
    "    if not headlines:\n",
    "        print(f\"No news found for {stock_symbol}\")\n",
    "        return\n",
    "\n",
    "    #print(f\"News headlines for {stock_symbol}:\\n\")\n",
    "\n",
    "    # Perform sentiment analysis on each headline\n",
    "    results = sentiment_analysis(headlines)\n",
    "\n",
    "    # Initialize lists to store sentiment and scores\n",
    "    sentiments = []\n",
    "    scores = []\n",
    "\n",
    "    for result in results:\n",
    "        score = result['score']\n",
    "        scores.append(score)\n",
    "        sentiment = result['label']\n",
    "        if sentiment == 'POSITIVE':\n",
    "            sentiments.append(1)\n",
    "        elif sentiment == 'NEGATIVE':\n",
    "            sentiments.append(-1)\n",
    "        else:\n",
    "            sentiments.append(0)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate the average sentiment score\n",
    "    average_sentiment = np.mean(sentiments)\n",
    "\n",
    "    # Determine overall sentiment\n",
    "    if average_sentiment > 0:\n",
    "      overall_sentiment = \"Positive\"\n",
    "    elif average_sentiment < 0:\n",
    "      overall_sentiment = \"Negative\"\n",
    "    else:\n",
    "      overall_sentiment = \"Neutral\"\n",
    "\n",
    "        # Print results\n",
    "    def average(numbers):\n",
    "     sum_of_numbers = sum(numbers)\n",
    "     average = (sum_of_numbers / len(numbers)) * 100\n",
    "     return average\n",
    "\n",
    "\n",
    "    number = average(scores)\n",
    "\n",
    "    #formatted_number = number.replace(\",\", \"\")\n",
    "    #formatted_overall_sentiment = overall_sentiment.replace(\",\", \"\")\n",
    "    #return formatted_number, formatted_overall_sentiment\n",
    "\n",
    "    return f\"{number:.2f}% | {overall_sentiment}\"\n",
    "\n",
    "\n",
    "    # Print results\n",
    "    #for i, headline in enumerate(headlines):\n",
    "        #sentiment = results[i]['label']\n",
    "        #score = results[i]['score']\n",
    "        #print(f\"Headline: {headline}\")\n",
    "        #print(f\"Sentiment: {sentiment}, Score: {score:.4f}\")\n",
    "        #print(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Example: Analyze sentiment on Apple (AAPL) stock news\n",
    "stock_symbol = \"AAPL\"\n",
    "num_articles = 5\n",
    "analyze_sentiment_on_news(stock_symbol, num_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combined Pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_pipelines(ticker, num_articles=None):\n",
    "  prediction_one = stock_pipeline(ticker)\n",
    "  if num_articles:\n",
    "    prediction_two = analyze_sentiment_on_news(ticker,num_articles)\n",
    "  else:\n",
    "    prediction_two = analyze_sentiment_on_news(ticker,5)\n",
    "  return prediction_one, prediction_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradio Interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "input_component_one = gr.Textbox(label=\"Input sequence (comma-separated numbers)\")\n",
    "input_component_two = gr.Textbox(label=\"Number of articles\")\n",
    "output_component_one = gr.Textbox(label=\"Stock Price Prediction\")\n",
    "output_component_two = gr.Textbox(label=\"Public Sentiment Score \")\n",
    "\n",
    "output_component = [output_component_one, output_component_two]\n",
    "\n",
    "interface = gr.Interface(fn= combined_pipelines, inputs=[input_component_one,input_component_two], outputs=[output_component_one, output_component_two])\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RyanDev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
