{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/stock_analysis.ipynb\n",
    "\n",
    "# Import system references\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure project_root is in the system path\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "#print(\"Project root added to sys.path:\", project_root in sys.path)\n",
    "#print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Logging\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import the fetch_stock_data function\n",
    "from scripts import fetch_stock_data, transform_stock_data_to_delta, transform_with_history\n",
    "from scripts import prepare_data_for_training, create_time_series_windows, gru_model, prepare_sliding_window_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SPY from 2021-01-01 to 2024-10-27\n"
     ]
    }
   ],
   "source": [
    "# Ask the user for a ticker symbol\n",
    "ticker = input(\"Please enter a stock ticker symbol (e.g., 'AAPL', 'SPY', 'QQQ', etc.): \").upper()\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = '2021-01-01'\n",
    "\n",
    "# If end_date is not provided, you can set it to today's date\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')  # Default to today's date if not specified\n",
    "\n",
    "# Print the ticker and date range to confirm\n",
    "print(f\"Fetching data for {ticker} from {start_date} to {end_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 13:28:04,412 - INFO - End date provided: 2024-10-27\n",
      "2024-10-27 13:28:04,412 - INFO - Fetching data for ticker: SPY from 2021-01-01 to 2024-10-27\n",
      "2024-10-27 13:28:08,966 - INFO - Resetting index to make 'Date' a column.\n",
      "2024-10-27 13:28:08,966 - INFO - Flattening multi-level column names (removing ticker symbol).\n",
      "2024-10-27 13:28:08,966 - INFO - Successfully fetched and simplified data for ticker 'SPY'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04 00:00:00+00:00</td>\n",
       "      <td>349.471619</td>\n",
       "      <td>368.790009</td>\n",
       "      <td>375.450012</td>\n",
       "      <td>364.820007</td>\n",
       "      <td>375.309998</td>\n",
       "      <td>110210800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05 00:00:00+00:00</td>\n",
       "      <td>351.878571</td>\n",
       "      <td>371.329987</td>\n",
       "      <td>372.500000</td>\n",
       "      <td>368.049988</td>\n",
       "      <td>368.100006</td>\n",
       "      <td>66426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 00:00:00+00:00</td>\n",
       "      <td>353.982300</td>\n",
       "      <td>373.549988</td>\n",
       "      <td>376.980011</td>\n",
       "      <td>369.119995</td>\n",
       "      <td>369.709991</td>\n",
       "      <td>107997700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07 00:00:00+00:00</td>\n",
       "      <td>359.241577</td>\n",
       "      <td>379.100006</td>\n",
       "      <td>379.899994</td>\n",
       "      <td>375.910004</td>\n",
       "      <td>376.100006</td>\n",
       "      <td>68766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08 00:00:00+00:00</td>\n",
       "      <td>361.288452</td>\n",
       "      <td>381.260010</td>\n",
       "      <td>381.489990</td>\n",
       "      <td>377.100006</td>\n",
       "      <td>380.589996</td>\n",
       "      <td>71677200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Date   Adj Close       Close        High  \\\n",
       "0     2021-01-04 00:00:00+00:00  349.471619  368.790009  375.450012   \n",
       "1     2021-01-05 00:00:00+00:00  351.878571  371.329987  372.500000   \n",
       "2     2021-01-06 00:00:00+00:00  353.982300  373.549988  376.980011   \n",
       "3     2021-01-07 00:00:00+00:00  359.241577  379.100006  379.899994   \n",
       "4     2021-01-08 00:00:00+00:00  361.288452  381.260010  381.489990   \n",
       "\n",
       "Price         Low        Open     Volume  \n",
       "0      364.820007  375.309998  110210800  \n",
       "1      368.049988  368.100006   66426200  \n",
       "2      369.119995  369.709991  107997700  \n",
       "3      375.910004  376.100006   68766800  \n",
       "4      377.100006  380.589996   71677200  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch stock data\n",
    "stock_data_df = fetch_stock_data(ticker, start_date, end_date)\n",
    "#stock_data_df = fetch_stock_data(ticker, start_date)\n",
    "\n",
    "# Check if data is fetched successfully\n",
    "if not stock_data_df.empty:\n",
    "    # Display the first few rows\n",
    "    display(stock_data_df.head())\n",
    "else:\n",
    "    print(\"No data to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 13:28:08,995 - INFO - Starting transformation of stock data to deltas.\n",
      "2024-10-27 13:28:08,995 - INFO - Dropping columns: ['Adj Close']\n",
      "2024-10-27 13:28:08,995 - INFO - Calculating deltas for specified columns: ['Open', 'High', 'Low', 'Close']\n",
      "2024-10-27 13:28:08,995 - INFO - Transforming column: Open\n",
      "2024-10-27 13:28:09,004 - INFO - Transforming column: High\n",
      "2024-10-27 13:28:09,008 - INFO - Transforming column: Low\n",
      "2024-10-27 13:28:09,009 - INFO - Transforming column: Close\n",
      "2024-10-27 13:28:09,013 - INFO - Dropping the first row with NaN values after delta calculation.\n",
      "2024-10-27 13:28:09,015 - INFO - Successfully transformed stock data to deltas.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open_delta</th>\n",
       "      <th>High_delta</th>\n",
       "      <th>Low_delta</th>\n",
       "      <th>Close_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05 00:00:00+00:00</td>\n",
       "      <td>371.329987</td>\n",
       "      <td>372.500000</td>\n",
       "      <td>368.049988</td>\n",
       "      <td>368.100006</td>\n",
       "      <td>66426200</td>\n",
       "      <td>-0.0192</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 00:00:00+00:00</td>\n",
       "      <td>373.549988</td>\n",
       "      <td>376.980011</td>\n",
       "      <td>369.119995</td>\n",
       "      <td>369.709991</td>\n",
       "      <td>107997700</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07 00:00:00+00:00</td>\n",
       "      <td>379.100006</td>\n",
       "      <td>379.899994</td>\n",
       "      <td>375.910004</td>\n",
       "      <td>376.100006</td>\n",
       "      <td>68766800</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08 00:00:00+00:00</td>\n",
       "      <td>381.260010</td>\n",
       "      <td>381.489990</td>\n",
       "      <td>377.100006</td>\n",
       "      <td>380.589996</td>\n",
       "      <td>71677200</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-11 00:00:00+00:00</td>\n",
       "      <td>378.690002</td>\n",
       "      <td>380.579987</td>\n",
       "      <td>377.720001</td>\n",
       "      <td>377.850006</td>\n",
       "      <td>51034700</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Date       Close        High         Low  \\\n",
       "1     2021-01-05 00:00:00+00:00  371.329987  372.500000  368.049988   \n",
       "2     2021-01-06 00:00:00+00:00  373.549988  376.980011  369.119995   \n",
       "3     2021-01-07 00:00:00+00:00  379.100006  379.899994  375.910004   \n",
       "4     2021-01-08 00:00:00+00:00  381.260010  381.489990  377.100006   \n",
       "5     2021-01-11 00:00:00+00:00  378.690002  380.579987  377.720001   \n",
       "\n",
       "Price        Open     Volume  Open_delta  High_delta  Low_delta  Close_delta  \n",
       "1      368.100006   66426200     -0.0192     -0.0079     0.0089       0.0069  \n",
       "2      369.709991  107997700      0.0044      0.0120     0.0029       0.0060  \n",
       "3      376.100006   68766800      0.0173      0.0077     0.0184       0.0149  \n",
       "4      380.589996   71677200      0.0119      0.0042     0.0032       0.0057  \n",
       "5      377.850006   51034700     -0.0072     -0.0024     0.0016      -0.0067  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform Stock Data to Deltas\n",
    "columns_to_exclude = ['Adj Close']  # Drop 'Adj Close'\n",
    "columns_to_keep = ['Volume']  # Keep 'Volume' but exclude from delta calculation\n",
    "columns_to_calculate = ['Open', 'High', 'Low', 'Close']  # Calculate deltas for 'Open' and 'Close'\n",
    "\n",
    "transformed_data_df = transform_stock_data_to_delta(\n",
    "    stock_data_df, \n",
    "    columns_to_exclude=columns_to_exclude, \n",
    "    columns_to_calculate=columns_to_calculate, \n",
    "    columns_to_keep=columns_to_keep\n",
    ")\n",
    "\n",
    "#transformed_data_df = transform_stock_data_to_delta(stock_data_df)\n",
    "#transformed_data_df = transform_stock_data_to_delta(stock_data_df, exclude=['Volume'])\n",
    "\n",
    "# Display Transformed Data\n",
    "if not transformed_data_df.empty:\n",
    "    display(transformed_data_df.head())\n",
    "else:\n",
    "    print(\"No transformed data to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Open_delta</th>\n",
       "      <th>High_delta</th>\n",
       "      <th>Low_delta</th>\n",
       "      <th>Close_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0192</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.0072</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price  Open_delta  High_delta  Low_delta  Close_delta\n",
       "1         -0.0192     -0.0079     0.0089       0.0069\n",
       "2          0.0044      0.0120     0.0029       0.0060\n",
       "3          0.0173      0.0077     0.0184       0.0149\n",
       "4          0.0119      0.0042     0.0032       0.0057\n",
       "5         -0.0072     -0.0024     0.0016      -0.0067"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the data by removing non-delta columns\n",
    "delta_only_df = prepare_sliding_window_data(transformed_data_df)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "display(delta_only_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of X:\n",
      " [[[-0.0192 -0.0079  0.0089  0.0069]\n",
      "  [ 0.0044  0.012   0.0029  0.006 ]\n",
      "  [ 0.0173  0.0077  0.0184  0.0149]\n",
      "  ...\n",
      "  [ 0.0072  0.0009  0.0013 -0.0022]\n",
      "  [-0.0035 -0.0026  0.0003  0.002 ]\n",
      "  [ 0.0031  0.0026  0.0029  0.0005]]\n",
      "\n",
      " [[ 0.0044  0.012   0.0029  0.006 ]\n",
      "  [ 0.0173  0.0077  0.0184  0.0149]\n",
      "  [ 0.0119  0.0042  0.0032  0.0057]\n",
      "  ...\n",
      "  [-0.0035 -0.0026  0.0003  0.002 ]\n",
      "  [ 0.0031  0.0026  0.0029  0.0005]\n",
      "  [ 0.0019  0.0013  0.0019  0.0018]]\n",
      "\n",
      " [[ 0.0173  0.0077  0.0184  0.0149]\n",
      "  [ 0.0119  0.0042  0.0032  0.0057]\n",
      "  [-0.0072 -0.0024  0.0016 -0.0067]\n",
      "  ...\n",
      "  [ 0.0031  0.0026  0.0029  0.0005]\n",
      "  [ 0.0019  0.0013  0.0019  0.0018]\n",
      "  [ 0.0038  0.0035 -0.0014 -0.0009]]\n",
      "\n",
      " [[ 0.0119  0.0042  0.0032  0.0057]\n",
      "  [-0.0072 -0.0024  0.0016 -0.0067]\n",
      "  [ 0.0028 -0.0019 -0.0036  0.0002]\n",
      "  ...\n",
      "  [ 0.0019  0.0013  0.0019  0.0018]\n",
      "  [ 0.0038  0.0035 -0.0014 -0.0009]\n",
      "  [-0.0052 -0.0035  0.0002  0.0016]]\n",
      "\n",
      " [[-0.0072 -0.0024  0.0016 -0.0067]\n",
      "  [ 0.0028 -0.0019 -0.0036  0.0002]\n",
      "  [-0.0005  0.0026  0.004   0.0027]\n",
      "  ...\n",
      "  [ 0.0038  0.0035 -0.0014 -0.0009]\n",
      "  [-0.0052 -0.0035  0.0002  0.0016]\n",
      "  [-0.006  -0.0029 -0.0072 -0.0037]]]\n",
      "First 5 entries of y:\n",
      " [ 0.0018 -0.0009  0.0016 -0.0037  0.0091]\n",
      "X_train shape: (687, 100, 4)\n",
      "X_test shape: (172, 100, 4)\n",
      "y_train shape: (687,)\n",
      "y_test shape: (172,)\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "n_timesteps = 100  # Number of timesteps (sequence length)\n",
    "\n",
    "# Step 1: Create the time series windows (X and y)\n",
    "X, y = create_time_series_windows(delta_only_df, 'Close_delta', n_timesteps)\n",
    "\n",
    "# Display the first few occurrences of the X and y arrays\n",
    "print(\"First 5 entries of X:\\n\", X[:5])  # Display first 5 rows\n",
    "print(\"First 5 entries of y:\\n\", y[:5])  # Display first 5 target values\n",
    "\n",
    "# Step 2: Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler for X and y values\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Reshape X data to 2D for scaling, keeping the last dimension as features\n",
    "n_samples_train = X_train.shape[0]\n",
    "n_samples_test = X_test.shape[0]\n",
    "\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])  # Reshape to 2D: [samples * timesteps, features]\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "# Apply scaling to X features (fit on X_train, transform both X_train and X_test)\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_reshaped).reshape(n_samples_train, X_train.shape[1], X_train.shape[2])\n",
    "X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(n_samples_test, X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "# Reshape y values to 2D (required by MinMaxScaler)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Apply scaling to y values\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mark.storer\\Documents\\Data\\AI\\Repositories\\Project_3a\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 11s - 481ms/step - loss: 0.2371 - val_loss: 0.2283\n",
      "Epoch 2/70\n",
      "22/22 - 3s - 141ms/step - loss: 0.2361 - val_loss: 0.2274\n",
      "Epoch 3/70\n",
      "22/22 - 3s - 149ms/step - loss: 0.2352 - val_loss: 0.2265\n",
      "Epoch 4/70\n",
      "22/22 - 3s - 135ms/step - loss: 0.2343 - val_loss: 0.2256\n",
      "Epoch 5/70\n",
      "22/22 - 3s - 125ms/step - loss: 0.2334 - val_loss: 0.2247\n",
      "Epoch 6/70\n",
      "22/22 - 3s - 122ms/step - loss: 0.2324 - val_loss: 0.2238\n",
      "Epoch 7/70\n",
      "22/22 - 3s - 118ms/step - loss: 0.2315 - val_loss: 0.2229\n",
      "Epoch 8/70\n",
      "22/22 - 3s - 125ms/step - loss: 0.2306 - val_loss: 0.2220\n",
      "Epoch 9/70\n",
      "22/22 - 3s - 154ms/step - loss: 0.2297 - val_loss: 0.2211\n",
      "Epoch 10/70\n",
      "22/22 - 3s - 141ms/step - loss: 0.2288 - val_loss: 0.2202\n",
      "Epoch 11/70\n",
      "22/22 - 3s - 139ms/step - loss: 0.2279 - val_loss: 0.2193\n",
      "Epoch 12/70\n",
      "22/22 - 3s - 129ms/step - loss: 0.2270 - val_loss: 0.2183\n",
      "Epoch 13/70\n",
      "22/22 - 3s - 135ms/step - loss: 0.2260 - val_loss: 0.2174\n",
      "Epoch 14/70\n",
      "22/22 - 3s - 139ms/step - loss: 0.2250 - val_loss: 0.2164\n",
      "Epoch 15/70\n",
      "22/22 - 3s - 138ms/step - loss: 0.2241 - val_loss: 0.2155\n",
      "Epoch 16/70\n",
      "22/22 - 3s - 123ms/step - loss: 0.2232 - val_loss: 0.2146\n",
      "Epoch 17/70\n",
      "22/22 - 3s - 118ms/step - loss: 0.2223 - val_loss: 0.2137\n",
      "Epoch 18/70\n",
      "22/22 - 3s - 128ms/step - loss: 0.2214 - val_loss: 0.2128\n",
      "Epoch 19/70\n",
      "22/22 - 3s - 120ms/step - loss: 0.2205 - val_loss: 0.2119\n",
      "Epoch 20/70\n",
      "22/22 - 3s - 126ms/step - loss: 0.2196 - val_loss: 0.2110\n",
      "Epoch 21/70\n",
      "22/22 - 3s - 122ms/step - loss: 0.2187 - val_loss: 0.2102\n",
      "Epoch 22/70\n",
      "22/22 - 3s - 123ms/step - loss: 0.2178 - val_loss: 0.2093\n",
      "Epoch 23/70\n",
      "22/22 - 3s - 120ms/step - loss: 0.2169 - val_loss: 0.2084\n",
      "Epoch 24/70\n",
      "22/22 - 3s - 122ms/step - loss: 0.2161 - val_loss: 0.2076\n",
      "Epoch 25/70\n",
      "22/22 - 3s - 125ms/step - loss: 0.2152 - val_loss: 0.2067\n",
      "Epoch 26/70\n",
      "22/22 - 3s - 141ms/step - loss: 0.2143 - val_loss: 0.2059\n",
      "Epoch 27/70\n",
      "22/22 - 3s - 134ms/step - loss: 0.2135 - val_loss: 0.2050\n",
      "Epoch 28/70\n",
      "22/22 - 3s - 154ms/step - loss: 0.2126 - val_loss: 0.2042\n",
      "Epoch 29/70\n",
      "22/22 - 3s - 137ms/step - loss: 0.2117 - val_loss: 0.2033\n",
      "Epoch 30/70\n",
      "22/22 - 3s - 125ms/step - loss: 0.2109 - val_loss: 0.2025\n",
      "Epoch 31/70\n",
      "22/22 - 3s - 123ms/step - loss: 0.2100 - val_loss: 0.2017\n",
      "Epoch 32/70\n",
      "22/22 - 3s - 119ms/step - loss: 0.2092 - val_loss: 0.2008\n",
      "Epoch 33/70\n",
      "22/22 - 3s - 125ms/step - loss: 0.2083 - val_loss: 0.2000\n",
      "Epoch 34/70\n",
      "22/22 - 3s - 124ms/step - loss: 0.2075 - val_loss: 0.1992\n",
      "Epoch 35/70\n",
      "22/22 - 3s - 121ms/step - loss: 0.2067 - val_loss: 0.1983\n",
      "Epoch 36/70\n",
      "22/22 - 3s - 130ms/step - loss: 0.2058 - val_loss: 0.1975\n",
      "Epoch 37/70\n",
      "22/22 - 3s - 138ms/step - loss: 0.2050 - val_loss: 0.1967\n",
      "Epoch 38/70\n",
      "22/22 - 3s - 142ms/step - loss: 0.2042 - val_loss: 0.1959\n",
      "Epoch 39/70\n",
      "22/22 - 3s - 137ms/step - loss: 0.2033 - val_loss: 0.1951\n",
      "Epoch 40/70\n",
      "22/22 - 3s - 130ms/step - loss: 0.2025 - val_loss: 0.1942\n",
      "Epoch 41/70\n",
      "22/22 - 3s - 133ms/step - loss: 0.2017 - val_loss: 0.1934\n",
      "Epoch 42/70\n",
      "22/22 - 3s - 142ms/step - loss: 0.2009 - val_loss: 0.1926\n",
      "Epoch 43/70\n",
      "22/22 - 3s - 143ms/step - loss: 0.2001 - val_loss: 0.1918\n",
      "Epoch 44/70\n",
      "22/22 - 3s - 157ms/step - loss: 0.1992 - val_loss: 0.1910\n",
      "Epoch 45/70\n",
      "22/22 - 4s - 160ms/step - loss: 0.1984 - val_loss: 0.1902\n",
      "Epoch 46/70\n",
      "22/22 - 4s - 181ms/step - loss: 0.1976 - val_loss: 0.1894\n",
      "Epoch 47/70\n",
      "22/22 - 4s - 177ms/step - loss: 0.1968 - val_loss: 0.1886\n",
      "Epoch 48/70\n",
      "22/22 - 4s - 166ms/step - loss: 0.1960 - val_loss: 0.1879\n",
      "Epoch 49/70\n",
      "22/22 - 4s - 175ms/step - loss: 0.1953 - val_loss: 0.1871\n",
      "Epoch 50/70\n",
      "22/22 - 4s - 162ms/step - loss: 0.1945 - val_loss: 0.1863\n",
      "Epoch 51/70\n",
      "22/22 - 4s - 169ms/step - loss: 0.1937 - val_loss: 0.1856\n",
      "Epoch 52/70\n",
      "22/22 - 4s - 196ms/step - loss: 0.1929 - val_loss: 0.1848\n",
      "Epoch 53/70\n",
      "22/22 - 4s - 173ms/step - loss: 0.1922 - val_loss: 0.1841\n",
      "Epoch 54/70\n",
      "22/22 - 4s - 168ms/step - loss: 0.1914 - val_loss: 0.1833\n",
      "Epoch 55/70\n",
      "22/22 - 5s - 225ms/step - loss: 0.1907 - val_loss: 0.1826\n",
      "Epoch 56/70\n",
      "22/22 - 3s - 157ms/step - loss: 0.1899 - val_loss: 0.1818\n",
      "Epoch 57/70\n",
      "22/22 - 3s - 152ms/step - loss: 0.1892 - val_loss: 0.1811\n",
      "Epoch 58/70\n",
      "22/22 - 3s - 155ms/step - loss: 0.1884 - val_loss: 0.1804\n",
      "Epoch 59/70\n",
      "22/22 - 3s - 154ms/step - loss: 0.1877 - val_loss: 0.1796\n",
      "Epoch 60/70\n",
      "22/22 - 3s - 154ms/step - loss: 0.1869 - val_loss: 0.1789\n",
      "Epoch 61/70\n",
      "22/22 - 4s - 184ms/step - loss: 0.1862 - val_loss: 0.1782\n",
      "Epoch 62/70\n",
      "22/22 - 4s - 175ms/step - loss: 0.1854 - val_loss: 0.1774\n",
      "Epoch 63/70\n",
      "22/22 - 4s - 173ms/step - loss: 0.1847 - val_loss: 0.1767\n",
      "Epoch 64/70\n",
      "22/22 - 4s - 159ms/step - loss: 0.1839 - val_loss: 0.1760\n",
      "Epoch 65/70\n",
      "22/22 - 3s - 155ms/step - loss: 0.1832 - val_loss: 0.1752\n",
      "Epoch 66/70\n",
      "22/22 - 3s - 152ms/step - loss: 0.1825 - val_loss: 0.1745\n",
      "Epoch 67/70\n",
      "22/22 - 4s - 161ms/step - loss: 0.1817 - val_loss: 0.1738\n",
      "Epoch 68/70\n",
      "22/22 - 3s - 149ms/step - loss: 0.1810 - val_loss: 0.1731\n",
      "Epoch 69/70\n",
      "22/22 - 3s - 139ms/step - loss: 0.1803 - val_loss: 0.1724\n",
      "Epoch 70/70\n",
      "22/22 - 3s - 137ms/step - loss: 0.1795 - val_loss: 0.1716\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "#n_timesteps = 25\n",
    "n_features = X_train_scaled.shape[2]\n",
    "\n",
    "# Define the number of layers and units per layer\n",
    "num_layers = 3\n",
    "units_per_layer = [50, 100, 50]  # 3 layers with 50, 100, and 50 units, respectively\n",
    "\n",
    "# Call the GRU model\n",
    "y_pred_scaled, model = gru_model(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, \n",
    "                                      n_timesteps, n_features, \n",
    "                                      num_layers, units_per_layer, \n",
    "                                      learning_rate=0.000001, epochs=70, batch_size=32)\n",
    "# Output the predictions\n",
    "#print(\"Predictions from GRU model:\", y_pred_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of y_pred_scaled [[0.03919066]\n",
      " [0.03643095]\n",
      " [0.03923596]\n",
      " [0.04106208]\n",
      " [0.03852762]]\n",
      "First 5 entries of y_pred_original [[-0.03963972]\n",
      " [-0.03991155]\n",
      " [-0.03963526]\n",
      " [-0.03945538]\n",
      " [-0.03970503]]\n",
      "First 5 entries of y_test_scaled [[0.37664975]\n",
      " [0.5177665 ]\n",
      " [0.41725888]\n",
      " [0.49137056]\n",
      " [0.76142132]]\n",
      "First 5 entries of y_test_original [[-0.0064]\n",
      " [ 0.0075]\n",
      " [-0.0024]\n",
      " [ 0.0049]\n",
      " [ 0.0315]]\n",
      "Mean Squared Error (MSE): 0.001665\n",
      "Root Mean Squared Error (RMSE): 0.040807\n",
      "Mean Absolute Error (MAE): 0.039379\n",
      "R-squared (R²): -13.521821\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Inverse transform the predicted and actual y values to the original scale\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "# Display the first few occurrences of prediction and test scaled and unscaled arrays\n",
    "print(\"First 5 entries of y_pred_scaled\", y_pred_scaled[:5])  # Display first 5 rows\n",
    "print(\"First 5 entries of y_pred_original\", y_pred_original[:5])  # Display first 5 rows\n",
    "print(\"First 5 entries of y_test_scaled\", y_test_scaled[:5])  # Display first 5 target values\n",
    "print(\"First 5 entries of y_test_original\", y_test_original[:5])  # Display first 5 target values\n",
    "\n",
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "# Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "# R-squared\n",
    "r2 = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "print(f\"R-squared (R²): {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to compare actual and predicted values\n",
    "comparison_df = pd.DataFrame({'Actual': y_test_original.flatten(), 'Predicted': y_pred_original.flatten()})\n",
    "# Calculate the difference (error)\n",
    "comparison_df['Difference'] = comparison_df['Actual'] - comparison_df['Predicted']\n",
    "#print(comparison_df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Sign Matches: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Get the sign of the actual and predicted values\n",
    "actual_sign = np.sign(comparison_df['Actual'])\n",
    "predicted_sign = np.sign(comparison_df['Predicted'])\n",
    "#print(actual_sign.head(25))\n",
    "#print(predicted_sign.head(25))\n",
    "# Check where the signs match\n",
    "sign_matches = actual_sign == predicted_sign\n",
    "#print(sign_matches.head(25))\n",
    "\n",
    "# Calculate the percentage of sign matches\n",
    "percentage_match = sign_matches.mean() * 100\n",
    "\n",
    "print(f\"Percentage of Sign Matches: {percentage_match :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Predicted Close descrease for tomorrow is -3.97%. Suggestion: SELL with 50.00% confidence\n"
     ]
    }
   ],
   "source": [
    "# Get the prediction for tomorrow's Close_delta\n",
    "\n",
    "\"\"\"\n",
    "Predict the next Close_delta based on the most recent n_timesteps of data.\n",
    "    \n",
    "Using:\n",
    "- model: The trained GRU model.\n",
    "- delta_only_df (pd.DataFrame): The DataFrame containing all historical data, including the latest Close_delta.\n",
    "- n_timesteps (int): The number of timesteps (sequence length) used in the model.\n",
    "- scaler_X: The scaler used to scale the features (X).\n",
    "- scaler_y: The scaler used to scale the target (y).\n",
    "\n",
    "Returns:\n",
    "- float: The predicted Close_delta for the next day.\n",
    "\"\"\"\n",
    "# Step 1: Extract the last n_timesteps rows from the data (to be used as input for prediction)\n",
    "last_window = delta_only_df[-n_timesteps:].values.reshape(1, n_timesteps, delta_only_df.shape[1])\n",
    "\n",
    "# Step 2: Scale the input features\n",
    "last_window_scaled = scaler_X.transform(last_window.reshape(-1, last_window.shape[-1])).reshape(1, n_timesteps, -1)\n",
    "\n",
    "# Step 3: Use the model to predict the next Close_delta (scaled)\n",
    "predicted_close_delta_scaled = model.predict(last_window_scaled)\n",
    "\n",
    "# Step 4: Inverse transform the prediction to get the original scale of Close_delta\n",
    "predicted_close_delta = scaler_y.inverse_transform(predicted_close_delta_scaled)\n",
    "\n",
    "predicted_close_delta = predicted_close_delta[0][0]  # Return the predicted value\n",
    "\n",
    "# Decision logic: Buy if positive, Sell if negative\n",
    "if predicted_close_delta > 0:\n",
    "    print(f\"Predicted Close increase for {ticker} tomorrow is {(predicted_close_delta * 100):.2f}%. Suggestion: BUY with {percentage_match :.2f}% confidence\")\n",
    "else:\n",
    "    print(f\"Predicted Close decrease for {ticker} tomorrow is {(predicted_close_delta * 100):.2f}%. Suggestion: SELL with {percentage_match :.2f}% confidence\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
