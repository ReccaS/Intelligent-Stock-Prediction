{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/Project_3a.ipynb\n",
    "\n",
    "# Import system references\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure project_root is in the system path\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "#print(\"Project root added to sys.path:\", project_root in sys.path)\n",
    "#print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Logging\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import the fetch_stock_data function\n",
    "from scripts import fetch_stock_data, transform_stock_data_to_delta, transform_with_history\n",
    "from scripts import prepare_data_for_training, create_time_series_windows, lstm_model, prepare_sliding_window_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for VTI from 2021-01-01 to 2024-10-28\n"
     ]
    }
   ],
   "source": [
    "# Ask the user for a ticker symbol\n",
    "ticker = input(\"Please enter a stock ticker symbol (e.g., 'AAPL', 'SPY', 'QQQ', etc.): \").upper()\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = '2021-01-01'\n",
    "\n",
    "# If end_date is not provided, you can set it to today's date\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')  # Default to today's date if not specified\n",
    "\n",
    "# Print the ticker and date range to confirm\n",
    "print(f\"Fetching data for {ticker} from {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 14:34:43,777 - INFO - End date provided: 2024-10-28\n",
      "2024-10-28 14:34:43,779 - INFO - Fetching data for ticker: VTI from 2021-01-01 to 2024-10-28\n",
      "2024-10-28 14:34:44,308 - INFO - Resetting index to make 'Date' a column.\n",
      "2024-10-28 14:34:44,310 - INFO - Flattening multi-level column names (removing ticker symbol).\n",
      "2024-10-28 14:34:44,310 - INFO - Successfully fetched and simplified data for ticker 'VTI'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04 00:00:00+00:00</td>\n",
       "      <td>181.573761</td>\n",
       "      <td>191.869995</td>\n",
       "      <td>195.429993</td>\n",
       "      <td>189.759995</td>\n",
       "      <td>195.389999</td>\n",
       "      <td>8825800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05 00:00:00+00:00</td>\n",
       "      <td>183.040573</td>\n",
       "      <td>193.419998</td>\n",
       "      <td>193.949997</td>\n",
       "      <td>191.419998</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>3894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 00:00:00+00:00</td>\n",
       "      <td>184.687225</td>\n",
       "      <td>195.160004</td>\n",
       "      <td>196.889999</td>\n",
       "      <td>192.460007</td>\n",
       "      <td>192.500000</td>\n",
       "      <td>6175700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07 00:00:00+00:00</td>\n",
       "      <td>187.649246</td>\n",
       "      <td>198.289993</td>\n",
       "      <td>198.619995</td>\n",
       "      <td>196.399994</td>\n",
       "      <td>196.419998</td>\n",
       "      <td>4830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08 00:00:00+00:00</td>\n",
       "      <td>188.557709</td>\n",
       "      <td>199.250000</td>\n",
       "      <td>199.460007</td>\n",
       "      <td>196.979996</td>\n",
       "      <td>199.139999</td>\n",
       "      <td>7538700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Date   Adj Close       Close        High  \\\n",
       "0     2021-01-04 00:00:00+00:00  181.573761  191.869995  195.429993   \n",
       "1     2021-01-05 00:00:00+00:00  183.040573  193.419998  193.949997   \n",
       "2     2021-01-06 00:00:00+00:00  184.687225  195.160004  196.889999   \n",
       "3     2021-01-07 00:00:00+00:00  187.649246  198.289993  198.619995   \n",
       "4     2021-01-08 00:00:00+00:00  188.557709  199.250000  199.460007   \n",
       "\n",
       "Price         Low        Open   Volume  \n",
       "0      189.759995  195.389999  8825800  \n",
       "1      191.419998  191.490005  3894000  \n",
       "2      192.460007  192.500000  6175700  \n",
       "3      196.399994  196.419998  4830900  \n",
       "4      196.979996  199.139999  7538700  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch stock data\n",
    "stock_data_df = fetch_stock_data(ticker, start_date, end_date)\n",
    "#stock_data_df = fetch_stock_data(ticker, start_date)\n",
    "\n",
    "# Check if data is fetched successfully\n",
    "if not stock_data_df.empty:\n",
    "    # Display the first few rows\n",
    "    display(stock_data_df.head())\n",
    "else:\n",
    "    print(\"No data to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 14:34:44,333 - INFO - Starting transformation of stock data to deltas.\n",
      "2024-10-28 14:34:44,334 - INFO - Dropping columns: ['Adj Close']\n",
      "2024-10-28 14:34:44,336 - INFO - Calculating deltas for specified columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "2024-10-28 14:34:44,337 - INFO - Transforming column: Open\n",
      "2024-10-28 14:34:44,339 - INFO - Transforming column: High\n",
      "2024-10-28 14:34:44,342 - INFO - Transforming column: Low\n",
      "2024-10-28 14:34:44,345 - INFO - Transforming column: Close\n",
      "2024-10-28 14:34:44,348 - INFO - Transforming column: Volume\n",
      "2024-10-28 14:34:44,350 - INFO - Dropping the first row with NaN values after delta calculation.\n",
      "2024-10-28 14:34:44,352 - INFO - Successfully transformed stock data to deltas.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open_delta</th>\n",
       "      <th>High_delta</th>\n",
       "      <th>Low_delta</th>\n",
       "      <th>Close_delta</th>\n",
       "      <th>Volume_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05 00:00:00+00:00</td>\n",
       "      <td>193.419998</td>\n",
       "      <td>193.949997</td>\n",
       "      <td>191.419998</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>3894000</td>\n",
       "      <td>-0.0200</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>-0.5588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 00:00:00+00:00</td>\n",
       "      <td>195.160004</td>\n",
       "      <td>196.889999</td>\n",
       "      <td>192.460007</td>\n",
       "      <td>192.500000</td>\n",
       "      <td>6175700</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07 00:00:00+00:00</td>\n",
       "      <td>198.289993</td>\n",
       "      <td>198.619995</td>\n",
       "      <td>196.399994</td>\n",
       "      <td>196.419998</td>\n",
       "      <td>4830900</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>-0.2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08 00:00:00+00:00</td>\n",
       "      <td>199.250000</td>\n",
       "      <td>199.460007</td>\n",
       "      <td>196.979996</td>\n",
       "      <td>199.139999</td>\n",
       "      <td>7538700</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.5605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-11 00:00:00+00:00</td>\n",
       "      <td>198.059998</td>\n",
       "      <td>199.059998</td>\n",
       "      <td>197.220001</td>\n",
       "      <td>197.419998</td>\n",
       "      <td>3858600</td>\n",
       "      <td>-0.0086</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>-0.4882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Date       Close        High         Low  \\\n",
       "1     2021-01-05 00:00:00+00:00  193.419998  193.949997  191.419998   \n",
       "2     2021-01-06 00:00:00+00:00  195.160004  196.889999  192.460007   \n",
       "3     2021-01-07 00:00:00+00:00  198.289993  198.619995  196.399994   \n",
       "4     2021-01-08 00:00:00+00:00  199.250000  199.460007  196.979996   \n",
       "5     2021-01-11 00:00:00+00:00  198.059998  199.059998  197.220001   \n",
       "\n",
       "Price        Open   Volume  Open_delta  High_delta  Low_delta  Close_delta  \\\n",
       "1      191.490005  3894000     -0.0200     -0.0076     0.0087       0.0081   \n",
       "2      192.500000  6175700      0.0053      0.0152     0.0054       0.0090   \n",
       "3      196.419998  4830900      0.0204      0.0088     0.0205       0.0160   \n",
       "4      199.139999  7538700      0.0138      0.0042     0.0030       0.0048   \n",
       "5      197.419998  3858600     -0.0086     -0.0020     0.0012      -0.0060   \n",
       "\n",
       "Price  Volume_delta  \n",
       "1           -0.5588  \n",
       "2            0.5860  \n",
       "3           -0.2178  \n",
       "4            0.5605  \n",
       "5           -0.4882  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform Stock Data to Deltas\n",
    "columns_to_exclude = ['Adj Close']  # Drop 'Adj Close'\n",
    "columns_to_keep = []  # Keep 'Volume' but exclude from delta calculation\n",
    "columns_to_calculate = ['Open', 'High', 'Low', 'Close', 'Volume']  # Calculate deltas for 'Open' and 'Close'\n",
    "\n",
    "transformed_data_df = transform_stock_data_to_delta(\n",
    "    stock_data_df, \n",
    "    columns_to_exclude=columns_to_exclude, \n",
    "    columns_to_calculate=columns_to_calculate, \n",
    "    columns_to_keep=columns_to_keep\n",
    ")\n",
    "\n",
    "#transformed_data_df = transform_stock_data_to_delta(stock_data_df)\n",
    "#transformed_data_df = transform_stock_data_to_delta(stock_data_df, exclude=['Volume'])\n",
    "\n",
    "# Display Transformed Data\n",
    "if not transformed_data_df.empty:\n",
    "    display(transformed_data_df.head())\n",
    "else:\n",
    "    print(\"No transformed data to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Open_delta</th>\n",
       "      <th>High_delta</th>\n",
       "      <th>Low_delta</th>\n",
       "      <th>Close_delta</th>\n",
       "      <th>Volume_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0200</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>-0.5588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>-0.2178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.5605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.0086</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>-0.4882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price  Open_delta  High_delta  Low_delta  Close_delta  Volume_delta\n",
       "1         -0.0200     -0.0076     0.0087       0.0081       -0.5588\n",
       "2          0.0053      0.0152     0.0054       0.0090        0.5860\n",
       "3          0.0204      0.0088     0.0205       0.0160       -0.2178\n",
       "4          0.0138      0.0042     0.0030       0.0048        0.5605\n",
       "5         -0.0086     -0.0020     0.0012      -0.0060       -0.4882"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the data by removing non-delta columns\n",
    "delta_only_df = prepare_sliding_window_data(transformed_data_df)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "display(delta_only_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of X:\n",
      " [[[-2.000e-02 -7.600e-03  8.700e-03  8.100e-03 -5.588e-01]\n",
      "  [ 5.300e-03  1.520e-02  5.400e-03  9.000e-03  5.860e-01]\n",
      "  [ 2.040e-02  8.800e-03  2.050e-02  1.600e-02 -2.178e-01]\n",
      "  ...\n",
      "  [ 7.400e-03  1.500e-03  1.300e-03 -2.800e-03  2.877e-01]\n",
      "  [-3.900e-03 -2.100e-03  1.300e-03  3.600e-03 -1.196e-01]\n",
      "  [ 4.700e-03  3.100e-03  5.100e-03  1.800e-03 -1.967e-01]]\n",
      "\n",
      " [[ 5.300e-03  1.520e-02  5.400e-03  9.000e-03  5.860e-01]\n",
      "  [ 2.040e-02  8.800e-03  2.050e-02  1.600e-02 -2.178e-01]\n",
      "  [ 1.380e-02  4.200e-03  3.000e-03  4.800e-03  5.605e-01]\n",
      "  ...\n",
      "  [-3.900e-03 -2.100e-03  1.300e-03  3.600e-03 -1.196e-01]\n",
      "  [ 4.700e-03  3.100e-03  5.100e-03  1.800e-03 -1.967e-01]\n",
      "  [ 2.800e-03  2.200e-03  2.000e-03  1.700e-03  7.100e-03]]\n",
      "\n",
      " [[ 2.040e-02  8.800e-03  2.050e-02  1.600e-02 -2.178e-01]\n",
      "  [ 1.380e-02  4.200e-03  3.000e-03  4.800e-03  5.605e-01]\n",
      "  [-8.600e-03 -2.000e-03  1.200e-03 -6.000e-03 -4.882e-01]\n",
      "  ...\n",
      "  [ 4.700e-03  3.100e-03  5.100e-03  1.800e-03 -1.967e-01]\n",
      "  [ 2.800e-03  2.200e-03  2.000e-03  1.700e-03  7.100e-03]\n",
      "  [ 4.300e-03  3.700e-03 -1.000e-03  4.000e-04  4.439e-01]]\n",
      "\n",
      " [[ 1.380e-02  4.200e-03  3.000e-03  4.800e-03  5.605e-01]\n",
      "  [-8.600e-03 -2.000e-03  1.200e-03 -6.000e-03 -4.882e-01]\n",
      "  [ 4.800e-03 -4.000e-04  6.000e-04  3.500e-03  4.000e-03]\n",
      "  ...\n",
      "  [ 2.800e-03  2.200e-03  2.000e-03  1.700e-03  7.100e-03]\n",
      "  [ 4.300e-03  3.700e-03 -1.000e-03  4.000e-04  4.439e-01]\n",
      "  [-4.100e-03 -3.200e-03  4.000e-04  1.300e-03 -5.420e-02]]\n",
      "\n",
      " [[-8.600e-03 -2.000e-03  1.200e-03 -6.000e-03 -4.882e-01]\n",
      "  [ 4.800e-03 -4.000e-04  6.000e-04  3.500e-03  4.000e-03]\n",
      "  [ 1.800e-03  3.000e-03  3.600e-03  1.100e-03 -1.054e-01]\n",
      "  ...\n",
      "  [ 4.300e-03  3.700e-03 -1.000e-03  4.000e-04  4.439e-01]\n",
      "  [-4.100e-03 -3.200e-03  4.000e-04  1.300e-03 -5.420e-02]\n",
      "  [-6.000e-03 -3.500e-03 -8.300e-03 -4.400e-03 -1.757e-01]]]\n",
      "First 5 entries of y:\n",
      " [ 0.0017  0.0004  0.0013 -0.0044  0.0087]\n",
      "X_train shape: (687, 100, 5)\n",
      "X_test shape: (172, 100, 5)\n",
      "y_train shape: (687,)\n",
      "y_test shape: (172,)\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "n_timesteps = 100  # Number of timesteps (sequence length)\n",
    "\n",
    "# Step 1: Create the time series windows (X and y)\n",
    "X, y = create_time_series_windows(delta_only_df, 'Close_delta', n_timesteps)\n",
    "\n",
    "# Display the first few occurrences of the X and y arrays\n",
    "print(\"First 5 entries of X:\\n\", X[:5])  # Display first 5 rows\n",
    "print(\"First 5 entries of y:\\n\", y[:5])  # Display first 5 target values\n",
    "\n",
    "# Step 2: Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler for X and y values\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Reshape X data to 2D for scaling, keeping the last dimension as features\n",
    "n_samples_train = X_train.shape[0]\n",
    "n_samples_test = X_test.shape[0]\n",
    "\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])  # Reshape to 2D: [samples * timesteps, features]\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "# Apply scaling to X features (fit on X_train, transform both X_train and X_test)\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_reshaped).reshape(n_samples_train, X_train.shape[1], X_train.shape[2])\n",
    "X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(n_samples_test, X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "# Reshape y values to 2D (required by MinMaxScaler)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Apply scaling to y values\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mark.storer\\Documents\\Data\\AI\\Repositories\\Project_3a\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 9s - 352ms/step - loss: 0.1982 - val_loss: 0.1854\n",
      "Epoch 2/70\n",
      "25/25 - 3s - 113ms/step - loss: 0.1889 - val_loss: 0.1764\n",
      "Epoch 3/70\n",
      "25/25 - 3s - 118ms/step - loss: 0.1798 - val_loss: 0.1676\n",
      "Epoch 4/70\n",
      "25/25 - 3s - 124ms/step - loss: 0.1711 - val_loss: 0.1591\n",
      "Epoch 5/70\n",
      "25/25 - 3s - 127ms/step - loss: 0.1624 - val_loss: 0.1508\n",
      "Epoch 6/70\n",
      "25/25 - 3s - 114ms/step - loss: 0.1543 - val_loss: 0.1429\n",
      "Epoch 7/70\n",
      "25/25 - 3s - 116ms/step - loss: 0.1462 - val_loss: 0.1349\n",
      "Epoch 8/70\n",
      "25/25 - 3s - 116ms/step - loss: 0.1378 - val_loss: 0.1265\n",
      "Epoch 9/70\n",
      "25/25 - 3s - 114ms/step - loss: 0.1292 - val_loss: 0.1179\n",
      "Epoch 10/70\n",
      "25/25 - 3s - 121ms/step - loss: 0.1203 - val_loss: 0.1092\n",
      "Epoch 11/70\n",
      "25/25 - 3s - 118ms/step - loss: 0.1112 - val_loss: 0.1001\n",
      "Epoch 12/70\n",
      "25/25 - 3s - 120ms/step - loss: 0.1017 - val_loss: 0.0907\n",
      "Epoch 13/70\n",
      "25/25 - 3s - 121ms/step - loss: 0.0919 - val_loss: 0.0809\n",
      "Epoch 14/70\n",
      "25/25 - 3s - 115ms/step - loss: 0.0816 - val_loss: 0.0706\n",
      "Epoch 15/70\n",
      "25/25 - 3s - 127ms/step - loss: 0.0708 - val_loss: 0.0600\n",
      "Epoch 16/70\n",
      "25/25 - 3s - 137ms/step - loss: 0.0595 - val_loss: 0.0491\n",
      "Epoch 17/70\n",
      "25/25 - 3s - 121ms/step - loss: 0.0481 - val_loss: 0.0382\n",
      "Epoch 18/70\n",
      "25/25 - 3s - 114ms/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 19/70\n",
      "25/25 - 3s - 116ms/step - loss: 0.0272 - val_loss: 0.0203\n",
      "Epoch 20/70\n",
      "25/25 - 3s - 118ms/step - loss: 0.0197 - val_loss: 0.0148\n",
      "Epoch 21/70\n",
      "25/25 - 3s - 114ms/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 22/70\n",
      "25/25 - 3s - 114ms/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 23/70\n",
      "25/25 - 3s - 115ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 24/70\n",
      "25/25 - 3s - 120ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 25/70\n",
      "25/25 - 3s - 126ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 26/70\n",
      "25/25 - 3s - 132ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 27/70\n",
      "25/25 - 4s - 157ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 28/70\n",
      "25/25 - 3s - 129ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 29/70\n",
      "25/25 - 4s - 159ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 30/70\n",
      "25/25 - 3s - 138ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 31/70\n",
      "25/25 - 3s - 105ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 32/70\n",
      "25/25 - 3s - 114ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 33/70\n",
      "25/25 - 3s - 115ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 34/70\n",
      "25/25 - 3s - 116ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 35/70\n",
      "25/25 - 3s - 126ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 36/70\n",
      "25/25 - 3s - 137ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 37/70\n",
      "25/25 - 3s - 124ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 38/70\n",
      "25/25 - 4s - 141ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 39/70\n",
      "25/25 - 3s - 120ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 40/70\n",
      "25/25 - 3s - 112ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 41/70\n",
      "25/25 - 3s - 112ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 42/70\n",
      "25/25 - 3s - 112ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 43/70\n",
      "25/25 - 3s - 120ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 44/70\n",
      "25/25 - 3s - 110ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 45/70\n",
      "25/25 - 3s - 120ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 46/70\n",
      "25/25 - 3s - 121ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 47/70\n",
      "25/25 - 3s - 137ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 48/70\n",
      "25/25 - 5s - 183ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 49/70\n",
      "25/25 - 3s - 117ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 50/70\n",
      "25/25 - 3s - 119ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 51/70\n",
      "25/25 - 3s - 112ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 52/70\n",
      "25/25 - 3s - 110ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 53/70\n",
      "25/25 - 3s - 126ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 54/70\n",
      "25/25 - 3s - 124ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 55/70\n",
      "25/25 - 3s - 110ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 56/70\n",
      "25/25 - 3s - 130ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 57/70\n",
      "25/25 - 3s - 117ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 58/70\n",
      "25/25 - 5s - 207ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 59/70\n",
      "25/25 - 3s - 131ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 60/70\n",
      "25/25 - 4s - 168ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 61/70\n",
      "25/25 - 4s - 151ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 62/70\n",
      "25/25 - 3s - 103ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 63/70\n",
      "25/25 - 2s - 92ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 64/70\n",
      "25/25 - 2s - 98ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 65/70\n",
      "25/25 - 2s - 100ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 66/70\n",
      "25/25 - 2s - 93ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 67/70\n",
      "25/25 - 2s - 98ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 68/70\n",
      "25/25 - 3s - 125ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 69/70\n",
      "25/25 - 3s - 137ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 70/70\n",
      "25/25 - 3s - 124ms/step - loss: 0.0126 - val_loss: 0.0122\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "#n_timesteps = 25\n",
    "n_features = X_train_scaled.shape[2]\n",
    "\n",
    "# Define the number of layers and units per layer\n",
    "num_layers = 3\n",
    "units_per_layer = [50, 100, 50]  # 3 layers with 50, 100, and 50 units, respectively\n",
    "\n",
    "# Call the LSTM model\n",
    "y_pred_scaled, model = lstm_model(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, n_timesteps, n_features, num_layers, units_per_layer, \n",
    "                         learning_rate=0.00001, epochs=70, batch_size=28)\n",
    "# Output the predictions\n",
    "#print(\"Predictions from LSTM model:\", y_pred_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of y_pred_scaled [[0.4498886 ]\n",
      " [0.42550546]\n",
      " [0.45606363]\n",
      " [0.43470904]\n",
      " [0.46578717]]\n",
      "First 5 entries of y_pred_original [[ 0.0018089 ]\n",
      " [-0.00061966]\n",
      " [ 0.00242394]\n",
      " [ 0.00029702]\n",
      " [ 0.0033924 ]]\n",
      "First 5 entries of y_test_scaled [[0.33935743]\n",
      " [0.50803213]\n",
      " [0.39056225]\n",
      " [0.4748996 ]\n",
      " [0.74096386]]\n",
      "First 5 entries of y_test_original [[-0.0092]\n",
      " [ 0.0076]\n",
      " [-0.0041]\n",
      " [ 0.0043]\n",
      " [ 0.0308]]\n",
      "Mean Squared Error (MSE): 0.000121\n",
      "Root Mean Squared Error (RMSE): 0.010996\n",
      "Mean Absolute Error (MAE): 0.008325\n",
      "R-squared (R²): -0.022483\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Inverse transform the predicted and actual y values to the original scale\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "# Display the first few occurrences of prediction and test scaled and unscaled arrays\n",
    "print(\"First 5 entries of y_pred_scaled\", y_pred_scaled[:5])  # Display first 5 rows\n",
    "print(\"First 5 entries of y_pred_original\", y_pred_original[:5])  # Display first 5 rows\n",
    "print(\"First 5 entries of y_test_scaled\", y_test_scaled[:5])  # Display first 5 target values\n",
    "print(\"First 5 entries of y_test_original\", y_test_original[:5])  # Display first 5 target values\n",
    "\n",
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "# Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "# R-squared\n",
    "r2 = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "print(f\"R-squared (R²): {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to compare actual and predicted values\n",
    "comparison_df = pd.DataFrame({'Actual': y_test_original.flatten(), 'Predicted': y_pred_original.flatten()})\n",
    "# Calculate the difference (error)\n",
    "comparison_df['Difference'] = comparison_df['Actual'] - comparison_df['Predicted']\n",
    "#print(comparison_df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3      True\n",
      "4      True\n",
      "      ...  \n",
      "95    False\n",
      "96     True\n",
      "97    False\n",
      "98     True\n",
      "99    False\n",
      "Length: 100, dtype: bool\n",
      "Percentage of Sign Matches: 55.23%\n"
     ]
    }
   ],
   "source": [
    "# Get the sign of the actual and predicted values\n",
    "actual_sign = np.sign(comparison_df['Actual'])\n",
    "predicted_sign = np.sign(comparison_df['Predicted'])\n",
    "#print(actual_sign.head(25))\n",
    "#print(predicted_sign.head(25))\n",
    "# Check where the signs match\n",
    "sign_matches = actual_sign == predicted_sign\n",
    "print(sign_matches.head(100))\n",
    "\n",
    "# Calculate the percentage of sign matches\n",
    "percentage_match = sign_matches.mean() * 100\n",
    "\n",
    "print(f\"Percentage of Sign Matches: {percentage_match :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Predicted Close increase for tomorrow is 0.30%. Suggestion: BUY with 55.23% confidence\n"
     ]
    }
   ],
   "source": [
    "# Get the prediction for tomorrow's Close_delta\n",
    "\n",
    "\"\"\"\n",
    "Predict the next Close_delta based on the most recent n_timesteps of data.\n",
    "    \n",
    "Using:\n",
    "- model: The trained LSTM model.\n",
    "- delta_only_df (pd.DataFrame): The DataFrame containing all historical data, including the latest Close_delta.\n",
    "- n_timesteps (int): The number of timesteps (sequence length) used in the model.\n",
    "- scaler_X: The scaler used to scale the features (X).\n",
    "- scaler_y: The scaler used to scale the target (y).\n",
    "\n",
    "Returns:\n",
    "- float: The predicted Close_delta for the next day.\n",
    "\"\"\"\n",
    "# Step 1: Extract the last n_timesteps rows from the data (to be used as input for prediction)\n",
    "last_window = delta_only_df[-n_timesteps:].values.reshape(1, n_timesteps, delta_only_df.shape[1])\n",
    "\n",
    "# Step 2: Scale the input features\n",
    "last_window_scaled = scaler_X.transform(last_window.reshape(-1, last_window.shape[-1])).reshape(1, n_timesteps, -1)\n",
    "\n",
    "# Step 3: Use the model to predict the next Close_delta (scaled)\n",
    "predicted_close_delta_scaled = model.predict(last_window_scaled)\n",
    "\n",
    "# Step 4: Inverse transform the prediction to get the original scale of Close_delta\n",
    "predicted_close_delta = scaler_y.inverse_transform(predicted_close_delta_scaled)\n",
    "\n",
    "predicted_close_delta = predicted_close_delta[0][0]  # Return the predicted value\n",
    "\n",
    "# Decision logic: Buy if positive, Sell if negative\n",
    "if predicted_close_delta > 0:\n",
    "    print(f\"Predicted Close increase for {ticker} tomorrow is {(predicted_close_delta * 100):.2f}%. Suggestion: BUY with {percentage_match :.2f}% confidence\")\n",
    "else:\n",
    "    print(f\"Predicted Close decrease for {ticker} tomorrow is {(predicted_close_delta * 100):.2f}%. Suggestion: SELL with {percentage_match :.2f}% confidence\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
