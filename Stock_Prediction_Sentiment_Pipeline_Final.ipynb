{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReccaS/Intelligent-Stock-Prediction/blob/main/Stock_Prediction_Sentiment_Pipeline_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaO2Q77EdN-w"
      },
      "outputs": [],
      "source": [
        "def stock_pipeline(user_input):\n",
        "    # notebooks/Project_3a.ipynb\n",
        "\n",
        "    # Import system references\n",
        "    import sys\n",
        "    import os\n",
        "\n",
        "    # Ensure project_root is in the system path\n",
        "    current_dir = os.getcwd()\n",
        "    project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.append(project_root)\n",
        "\n",
        "    #print(\"Project root added to sys.path:\", project_root in sys.path)\n",
        "    #print(sys.path)\n",
        "\n",
        "    #setup Logging\n",
        "    import logging\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.StreamHandler()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "    #setup Logging\n",
        "    import logging\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.StreamHandler()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "    # Import necessary libraries\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    from datetime import datetime\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, Dense\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "    # Import the fetch_stock_data function (for script-based pipeline only)\n",
        "\n",
        "    #from scripts import fetch_stock_data, transform_stock_data_to_delta, transform_with_history\n",
        "    #from scripts import prepare_data_for_training, create_time_series_windows, lstm_model, prepare_sliding_window_data\n",
        "\n",
        "\n",
        " #import function dependencies\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    def create_time_series_windows(data, target_column, n_timesteps):\n",
        "        \"\"\"\n",
        "        Creates sliding windows of data for time series prediction, including the target column (e.g., Close_delta)\n",
        "        in the feature set but shifting the target y to predict the next Close_delta value.\n",
        "\n",
        "        Parameters:\n",
        "        - data (pd.DataFrame): The original DataFrame containing all the features and the target.\n",
        "        - target_column (str): The name of the target column (e.g., 'Close_delta').\n",
        "        - n_timesteps (int): The number of timesteps (sequence length) for each window.\n",
        "\n",
        "        Returns:\n",
        "        - X (np.ndarray): The array of feature windows, including Close_delta.\n",
        "        - y (np.ndarray): The array of target values (Close_delta for the next time step).\n",
        "        \"\"\"\n",
        "        #import function dependencies\n",
        "        import numpy as np\n",
        "        import pandas as pd\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        # Loop through the data to create windows\n",
        "        for i in range(len(data) - n_timesteps):\n",
        "            # Include the target column in X (do not drop Close_delta)\n",
        "            X_window = data.iloc[i:i + n_timesteps].values  # Include all features, including Close_delta\n",
        "            y_window = data.iloc[i + n_timesteps][target_column]  # The target value is the next Close_delta\n",
        "\n",
        "            X.append(X_window)\n",
        "            y.append(y_window)\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def prepare_data_for_training_with_windows(transformed_with_history_df: pd.DataFrame, target_column: str, n_timesteps: int):\n",
        "        \"\"\"\n",
        "        Prepares the transformed DataFrame by generating time series windows and splitting them\n",
        "        into training and testing sets with an 80/20 ratio.\n",
        "\n",
        "        Parameters:\n",
        "        - transformed_with_history_df (pd.DataFrame): The DataFrame containing the transformed historical data.\n",
        "        - target_column (str): The name of the target column (e.g., 'Close_delta').\n",
        "        - n_timesteps (int): The number of timesteps (sequence length) for each window.\n",
        "\n",
        "        Returns:\n",
        "        - X_train (np.ndarray): Training set features.\n",
        "        - X_test (np.ndarray): Testing set features.\n",
        "        - y_train (np.ndarray): Training set target.\n",
        "        - y_test (np.ndarray): Testing set target.\n",
        "        \"\"\"\n",
        "\n",
        "        # Step 1: Create time series windows\n",
        "        X, y = create_time_series_windows(transformed_with_history_df, target_column, n_timesteps)\n",
        "\n",
        "        # Step 2: Randomly split the windows into training and testing sets (80/20 split)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    import yfinance as yf\n",
        "    import pandas as pd\n",
        "    from typing import Optional\n",
        "    import logging\n",
        "    from datetime import datetime\n",
        "\n",
        "    def fetch_stock_data(\n",
        "        ticker: str = 'SPY',\n",
        "        start_date: str = '2024-01-01',\n",
        "        end_date: Optional[str] = None\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Fetches historical stock data for a given ticker symbol between specified dates.\n",
        "        Ensures that ticker symbols are removed from column names if included.\n",
        "\n",
        "        Parameters:\n",
        "        - ticker (str, optional): The stock ticker symbol (default is 'SPY').\n",
        "        - start_date (str, optional): The start date in 'YYYY-MM-DD' format (default is '2024-01-01').\n",
        "        - end_date (Optional[str], optional): The end date in 'YYYY-MM-DD' format.\n",
        "        If not provided, defaults to the current date.\n",
        "\n",
        "        Returns:\n",
        "        - pd.DataFrame: A DataFrame containing the stock data with simplified column names.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        logger = logging.getLogger(__name__)  # Get a logger for this module\n",
        "\n",
        "        try:\n",
        "            # If end_date is not provided, set it to today's date\n",
        "            if end_date is None:\n",
        "                end_date = datetime.today().strftime('%Y-%m-%d')\n",
        "                logger.info(f\"No end_date provided. Using current date: {end_date}\")\n",
        "            else:\n",
        "                logger.info(f\"End date provided: {end_date}\")\n",
        "\n",
        "            logger.info(f\"Fetching data for ticker: {ticker} from {start_date} to {end_date}\")\n",
        "\n",
        "            # Download data with ticker as a string to get single-level or multi-level columns\n",
        "            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "\n",
        "            if data.empty:\n",
        "                logger.warning(f\"No data found for ticker '{ticker}' between {start_date} and {end_date}.\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            # Reset the index to make Date a column\n",
        "            logger.info(\"Resetting index to make 'Date' a column.\")\n",
        "            data = data.reset_index()\n",
        "\n",
        "            # Flatten column names if they are multi-level (i.e., contain the ticker symbol)\n",
        "            if isinstance(data.columns, pd.MultiIndex):\n",
        "                logger.info(\"Flattening multi-level column names (removing ticker symbol).\")\n",
        "                data.columns = data.columns.get_level_values(0)  # Keep only the first level (e.g., 'Close')\n",
        "\n",
        "            logger.info(f\"Successfully fetched and simplified data for ticker '{ticker}'.\")\n",
        "            return data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching data for ticker '{ticker}': {e}\")\n",
        "            return pd.DataFrame()  # Return empty DataFrame on failure\n",
        "\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    def prepare_sliding_window_data(transformed_data_df: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Prepares the data by dropping the specified columns and keeping only the delta values.\n",
        "\n",
        "        Parameters:\n",
        "        - transformed_data_df (pd.DataFrame): The DataFrame containing the transformed historical data.\n",
        "\n",
        "        Returns:\n",
        "        - pd.DataFrame: The DataFrame containing only the delta values.\n",
        "        \"\"\"\n",
        "        # Columns to drop\n",
        "        columns_to_drop = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
        "\n",
        "        # Drop the specified columns and return only delta values\n",
        "        delta_columns_df = transformed_data_df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "        return delta_columns_df\n",
        "\n",
        "\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    import pandas as pd\n",
        "\n",
        "    def prepare_data_for_training(transformed_with_history_df: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Prepares the transformed DataFrame by dropping the original High and Low columns (not delta ones)\n",
        "        and splitting the data into training and testing sets with an 80/20 ratio.\n",
        "\n",
        "        Returns both feature sets (X) and target sets (y).\n",
        "\n",
        "        Parameters:\n",
        "        - transformed_with_history_df (pd.DataFrame): The DataFrame containing the transformed historical data.\n",
        "\n",
        "        Returns:\n",
        "        - X_train (pd.DataFrame): Training set features.\n",
        "        - X_test (pd.DataFrame): Testing set features.\n",
        "        - y_train (pd.Series): Training set target.\n",
        "        - y_test (pd.Series): Testing set target.\n",
        "        \"\"\"\n",
        "        # Step 1: Drop only the original 'High' and 'Low' columns (not the delta columns)\n",
        "        columns_to_drop = ['High_delta', 'Low_delta']  # Exact column names to drop\n",
        "        cleaned_df = transformed_with_history_df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "        # Step 2: Extract Close_delta as the target variable\n",
        "        X = cleaned_df.drop(columns=['Close_delta'])  # Features (all columns except 'Close_delta')\n",
        "        y = cleaned_df['Close_delta']  # Target variable\n",
        "\n",
        "        # Step 3: Split the cleaned DataFrame into training and testing sets (80/20 split)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "    # scripts/transform_stock_data.py\n",
        "\n",
        "    import pandas as pd\n",
        "    from typing import Optional, List\n",
        "    import logging\n",
        "\n",
        "    # Initialize a logger for this module\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def transform_stock_data_to_delta(\n",
        "        df: pd.DataFrame,\n",
        "        columns_to_exclude: Optional[List[str]] = None,\n",
        "        columns_to_calculate: Optional[List[str]] = None,\n",
        "        columns_to_keep: Optional[List[str]] = None\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Transforms the stock data by excluding specified columns, keeping certain columns\n",
        "        without calculation, and calculating the proportion of increase or decrease (delta)\n",
        "        from the prior row value for specified columns. Increases are positive, decreases\n",
        "        are negative, and no change is zero.\n",
        "\n",
        "        Parameters:\n",
        "        - df (pd.DataFrame): The input DataFrame containing stock data.\n",
        "        - columns_to_exclude (Optional[List[str]], optional): List of column names to drop from the DataFrame.\n",
        "        - columns_to_calculate (Optional[List[str]], optional): List of column names to calculate deltas for.\n",
        "        If None, all numeric columns except those in 'columns_to_exclude' and 'columns_to_keep' will be transformed.\n",
        "        - columns_to_keep (Optional[List[str]], optional): List of column names to keep in the DataFrame but exclude from delta calculation.\n",
        "\n",
        "        Returns:\n",
        "        - pd.DataFrame: A DataFrame with the specified columns transformed to deltas, with certain columns excluded and others kept as-is.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting transformation of stock data to deltas.\")\n",
        "\n",
        "        try:\n",
        "            # Step 1: Drop columns to exclude\n",
        "            if columns_to_exclude:\n",
        "                logger.info(f\"Dropping columns: {columns_to_exclude}\")\n",
        "                df = df.drop(columns=columns_to_exclude, errors='ignore')\n",
        "            else:\n",
        "                logger.info(\"No columns specified for exclusion.\")\n",
        "\n",
        "            # Step 2: Select columns for delta calculation\n",
        "            if columns_to_calculate is None:\n",
        "                # Automatically select all numeric columns except those in columns_to_keep\n",
        "                numeric_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
        "                columns_to_calculate = [col for col in numeric_columns if col not in (columns_to_keep or [])]\n",
        "                logger.info(f\"No specific columns provided for delta calculation. Automatically selected: {columns_to_calculate}\")\n",
        "            else:\n",
        "                # Validate that specified columns exist in the DataFrame\n",
        "                missing_cols = [col for col in columns_to_calculate if col not in df.columns]\n",
        "                if missing_cols:\n",
        "                    logger.error(f\"The following specified columns for calculation are not in the DataFrame: {missing_cols}\")\n",
        "                    raise ValueError(f\"Missing columns for calculation: {missing_cols}\")\n",
        "                logger.info(f\"Calculating deltas for specified columns: {columns_to_calculate}\")\n",
        "\n",
        "            # Step 3: Create a copy to avoid modifying the original DataFrame\n",
        "            transformed_df = df.copy()\n",
        "\n",
        "            # Step 4: Calculate delta (proportion change) for each specified column\n",
        "            for col in columns_to_calculate:\n",
        "                logger.info(f\"Transforming column: {col}\")\n",
        "                # Compute the difference from the previous row and divide by the previous row's value\n",
        "                transformed_df[f\"{col}_delta\"] = transformed_df[col].diff() / transformed_df[col].shift(1)\n",
        "\n",
        "                # Round the delta values for better readability (optional)\n",
        "                transformed_df[f\"{col}_delta\"] = transformed_df[f\"{col}_delta\"].round(4)\n",
        "\n",
        "            # Step 5: Drop the first row as it will contain NaN values after diff()\n",
        "            logger.info(\"Dropping the first row with NaN values after delta calculation.\")\n",
        "            transformed_df = transformed_df.dropna()\n",
        "\n",
        "            logger.info(\"Successfully transformed stock data to deltas.\")\n",
        "            return transformed_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"An error occurred while transforming stock data: {e}\")\n",
        "            raise  # Re-raise the exception after logging\n",
        "\n",
        "    def transform_with_history(transformed_df: pd.DataFrame, history_length: int = 25) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Adds history columns to the transformed data by keeping only specific columns and\n",
        "        appending the delta values for the past 'history_length' rows as new columns.\n",
        "\n",
        "        Parameters:\n",
        "        - transformed_df (pd.DataFrame): The transformed DataFrame containing delta columns.\n",
        "        - history_length (int): The number of historical rows to append as new columns. Default is 25.\n",
        "\n",
        "        Returns:\n",
        "        - pd.DataFrame: A DataFrame with the historical delta values appended as new columns.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Starting transformation with {history_length} rows of history.\")\n",
        "\n",
        "        # Step 1: Keep only the 'Date', 'Open_delta', 'High_delta', 'Low_delta', and 'Close_delta' columns\n",
        "        columns_to_keep = ['Date', 'Open_delta', 'High_delta', 'Low_delta', 'Close_delta']\n",
        "\n",
        "        # Check if the required columns are present in the DataFrame\n",
        "        missing_cols = [col for col in columns_to_keep if col not in transformed_df.columns]\n",
        "        if missing_cols:\n",
        "            logger.error(f\"Missing columns: {missing_cols} in transformed_df\")\n",
        "            raise ValueError(f\"Required columns are missing: {missing_cols}\")\n",
        "\n",
        "        # Create a new DataFrame with the selected columns\n",
        "        transformed_with_history_df = transformed_df[columns_to_keep].copy()\n",
        "\n",
        "        # Step 2: Append historical columns using shift\n",
        "        for i in range(1, history_length):\n",
        "            logger.info(f\"Adding historical columns for lag: {i}\")\n",
        "\n",
        "            # Shift each delta column by i rows and create new column names\n",
        "            transformed_with_history_df[f'Open_delta-{i}'] = transformed_df['Open_delta'].shift(i)\n",
        "            transformed_with_history_df[f'High_delta-{i}'] = transformed_df['High_delta'].shift(i)\n",
        "            transformed_with_history_df[f'Low_delta-{i}'] = transformed_df['Low_delta'].shift(i)\n",
        "            transformed_with_history_df[f'Close_delta-{i}'] = transformed_df['Close_delta'].shift(i)\n",
        "\n",
        "        # Step 3: Drop rows that have NaN values due to shifting (i.e., the first 'history_length' rows)\n",
        "        transformed_with_history_df = transformed_with_history_df.dropna().reset_index(drop=True)\n",
        "\n",
        "        logger.info(\"Successfully transformed data with historical columns.\")\n",
        "\n",
        "        return transformed_with_history_df\n",
        "\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, Dense\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "    def lstm_model(X_train, y_train, X_test, y_test, n_timesteps, n_features, num_layers, units_per_layer,\n",
        "                learning_rate=0.001, epochs=20, batch_size=32):\n",
        "        \"\"\"\n",
        "        LSTM model for time series prediction with configurable layers, learning rate, epochs, and batch size.\n",
        "\n",
        "        Parameters:\n",
        "        - X_train (np.ndarray): Training features.\n",
        "        - y_train (np.ndarray): Training target.\n",
        "        - X_test (np.ndarray): Testing features.\n",
        "        - y_test (np.ndarray): Testing target.\n",
        "        - n_timesteps (int): Number of timesteps in each sequence.\n",
        "        - n_features (int): Number of features in each sequence.\n",
        "        - num_layers (int): Number of LSTM layers.\n",
        "        - units_per_layer (list of int): Number of units in each LSTM layer.\n",
        "        - learning_rate (float, optional): Learning rate for the Adam optimizer.\n",
        "        - epochs (int, optional): Number of epochs for training the model.\n",
        "        - batch_size (int, optional): Batch size for model training.\n",
        "\n",
        "        Returns:\n",
        "        - y_pred (np.ndarray): Predicted target values for the test set.\n",
        "        \"\"\"\n",
        "        assert len(units_per_layer) == num_layers, \"Length of `units_per_layer` must match `num_layers`\"\n",
        "\n",
        "        # Reshape the data for LSTM (3D shape: [samples, timesteps, features])\n",
        "        X_train = X_train.reshape((X_train.shape[0], n_timesteps, n_features))\n",
        "        X_test = X_test.reshape((X_test.shape[0], n_timesteps, n_features))\n",
        "\n",
        "        # Build LSTM model\n",
        "        model = Sequential()\n",
        "\n",
        "        # Add LSTM layers dynamically based on `num_layers` and `units_per_layer`\n",
        "        for i in range(num_layers):\n",
        "            if i == num_layers - 1:  # Last layer should not return sequences\n",
        "                model.add(LSTM(units_per_layer[i], activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "            else:  # Intermediate layers should return sequences\n",
        "                model.add(LSTM(units_per_layer[i], activation='relu', return_sequences=True))\n",
        "\n",
        "        # Add output Dense layer\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        # Compile the model with the Adam optimizer and mean squared error loss\n",
        "        model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
        "\n",
        "        # Train the model with the provided epochs and batch size\n",
        "        model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=2)\n",
        "\n",
        "        # Predict and evaluate\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        return y_pred, model\n",
        "\n",
        "    # Ask the user for a ticker symbol\n",
        "    ticker = user_input\n",
        "\n",
        "    # Define start and end dates\n",
        "    start_date = '2021-01-01'\n",
        "\n",
        "    # If end_date is not provided, you can set it to today's date\n",
        "    end_date = datetime.today().strftime('%Y-%m-%d')  # Default to today's date if not specified\n",
        "\n",
        "    # Print the ticker and date range to confirm\n",
        "    print(f\"Fetching data for {ticker} from {start_date} to {end_date}\")\n",
        "\n",
        "    # Fetch stock data\n",
        "    stock_data_df = fetch_stock_data(ticker, start_date, end_date)\n",
        "    #stock_data_df = fetch_stock_data(ticker, start_date)\n",
        "\n",
        "    # Check if data is fetched successfully\n",
        "    if not stock_data_df.empty:\n",
        "        # Display the first few rows\n",
        "        display(stock_data_df.head())\n",
        "    else:\n",
        "        print(\"No data to display.\")\n",
        "\n",
        "\n",
        "    # Transform Stock Data to Deltas\n",
        "    columns_to_exclude = ['Adj Close']  # Drop 'Adj Close'\n",
        "    columns_to_keep = []  # Keep 'Volume' but exclude from delta calculation\n",
        "    columns_to_calculate = ['Open', 'High', 'Low', 'Close', 'Volume']  # Calculate deltas for 'Open' and 'Close'\n",
        "\n",
        "    transformed_data_df = transform_stock_data_to_delta(\n",
        "        stock_data_df,\n",
        "        columns_to_exclude=columns_to_exclude,\n",
        "        columns_to_calculate=columns_to_calculate,\n",
        "        columns_to_keep=columns_to_keep\n",
        "    )\n",
        "\n",
        "    #transformed_data_df = transform_stock_data_to_delta(stock_data_df)\n",
        "    #transformed_data_df = transform_stock_data_to_delta(stock_data_df, exclude=['Volume'])\n",
        "\n",
        "    # Display Transformed Data\n",
        "    if not transformed_data_df.empty:\n",
        "        display(transformed_data_df.head())\n",
        "    else:\n",
        "        print(\"No transformed data to display.\")\n",
        "\n",
        "    # Prepare the data by removing non-delta columns\n",
        "    delta_only_df = prepare_sliding_window_data(transformed_data_df)\n",
        "\n",
        "    # Display the first few rows of the resulting DataFrame\n",
        "    display(delta_only_df.head())\n",
        "\n",
        "    # Define parameters\n",
        "    n_timesteps = 100  # Number of timesteps (sequence length)\n",
        "\n",
        "    # Step 1: Create the time series windows (X and y)\n",
        "    X, y = create_time_series_windows(delta_only_df, 'Close_delta', n_timesteps)\n",
        "\n",
        "    # Display the first few occurrences of the X and y arrays\n",
        "    print(\"First 5 entries of X:\\n\", X[:5])  # Display first 5 rows\n",
        "    print(\"First 5 entries of y:\\n\", y[:5])  # Display first 5 target values\n",
        "\n",
        "    # Step 2: Split the data into training and testing sets (80/20 split)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "    # Display the shapes of the training and testing sets\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"X_test shape:\", X_test.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "    # Initialize the scaler for X and y values\n",
        "    scaler_X = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    # Reshape X data to 2D for scaling, keeping the last dimension as features\n",
        "    n_samples_train = X_train.shape[0]\n",
        "    n_samples_test = X_test.shape[0]\n",
        "\n",
        "    X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])  # Reshape to 2D: [samples * timesteps, features]\n",
        "    X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "    # Apply scaling to X features (fit on X_train, transform both X_train and X_test)\n",
        "    X_train_scaled = scaler_X.fit_transform(X_train_reshaped).reshape(n_samples_train, X_train.shape[1], X_train.shape[2])\n",
        "    X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(n_samples_test, X_test.shape[1], X_test.shape[2])\n",
        "\n",
        "    # Reshape y values to 2D (required by MinMaxScaler)\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "    # Apply scaling to y values\n",
        "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "    y_test_scaled = scaler_y.transform(y_test)\n",
        "\n",
        "\n",
        "    # Define parameters\n",
        "    #n_timesteps = 25\n",
        "    n_features = X_train_scaled.shape[2]\n",
        "\n",
        "    # Define the number of layers and units per layer\n",
        "    num_layers = 3\n",
        "    units_per_layer = [50, 100, 50]  # 3 layers with 50, 100, and 50 units, respectively\n",
        "\n",
        "    # Call the LSTM model\n",
        "    y_pred_scaled, model = lstm_model(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, n_timesteps, n_features, num_layers, units_per_layer,\n",
        "                            learning_rate=0.00001, epochs=70, batch_size=28)\n",
        "    # Output the predictions\n",
        "    #print(\"Predictions from LSTM model:\", y_pred_scaled)\n",
        "\n",
        "    # Step 1: Inverse transform the predicted and actual y values to the original scale\n",
        "    y_pred_original = scaler_y.inverse_transform(y_pred_scaled)\n",
        "    y_test_original = scaler_y.inverse_transform(y_test_scaled)\n",
        "\n",
        "    # Display the first few occurrences of prediction and test scaled and unscaled arrays\n",
        "    print(\"First 5 entries of y_pred_scaled\", y_pred_scaled[:5])  # Display first 5 rows\n",
        "    print(\"First 5 entries of y_pred_original\", y_pred_original[:5])  # Display first 5 rows\n",
        "    print(\"First 5 entries of y_test_scaled\", y_test_scaled[:5])  # Display first 5 target values\n",
        "    print(\"First 5 entries of y_test_original\", y_test_original[:5])  # Display first 5 target values\n",
        "\n",
        "    # Mean Squared Error\n",
        "    mse = mean_squared_error(y_test_original, y_pred_original)\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(y_test_original, y_pred_original)\n",
        "    # R-squared\n",
        "    r2 = r2_score(y_test_original, y_pred_original)\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
        "    print(f\"R-squared (R²): {r2:.6f}\")\n",
        "\n",
        "\n",
        "    # Create a DataFrame to compare actual and predicted values\n",
        "    comparison_df = pd.DataFrame({'Actual': y_test_original.flatten(), 'Predicted': y_pred_original.flatten()})\n",
        "    # Calculate the difference (error)\n",
        "    comparison_df['Difference'] = comparison_df['Actual'] - comparison_df['Predicted']\n",
        "    #print(comparison_df.head(25))\n",
        "\n",
        "\n",
        "    # Get the sign of the actual and predicted values\n",
        "    actual_sign = np.sign(comparison_df['Actual'])\n",
        "    predicted_sign = np.sign(comparison_df['Predicted'])\n",
        "    #print(actual_sign.head(25))\n",
        "    #print(predicted_sign.head(25))\n",
        "    # Check where the signs match\n",
        "    sign_matches = actual_sign == predicted_sign\n",
        "    print(sign_matches.head(100))\n",
        "\n",
        "    # Calculate the percentage of sign matches\n",
        "    percentage_match = sign_matches.mean() * 100\n",
        "\n",
        "    print(f\"Percentage of Sign Matches: {percentage_match :.2f}%\")\n",
        "\n",
        "\n",
        "    # Get the prediction for tomorrow's Close_delta\n",
        "\n",
        "    \"\"\"\n",
        "    Predict the next Close_delta based on the most recent n_timesteps of data.\n",
        "\n",
        "    Using:\n",
        "    - model: The trained LSTM model.\n",
        "    - delta_only_df (pd.DataFrame): The DataFrame containing all historical data, including the latest Close_delta.\n",
        "    - n_timesteps (int): The number of timesteps (sequence length) used in the model.\n",
        "    - scaler_X: The scaler used to scale the features (X).\n",
        "    - scaler_y: The scaler used to scale the target (y).\n",
        "\n",
        "    Returns:\n",
        "    - float: The predicted Close_delta for the next day.\n",
        "    \"\"\"\n",
        "    # Step 1: Extract the last n_timesteps rows from the data (to be used as input for prediction)\n",
        "    last_window = delta_only_df[-n_timesteps:].values.reshape(1, n_timesteps, delta_only_df.shape[1])\n",
        "\n",
        "    # Step 2: Scale the input features\n",
        "    last_window_scaled = scaler_X.transform(last_window.reshape(-1, last_window.shape[-1])).reshape(1, n_timesteps, -1)\n",
        "\n",
        "    # Step 3: Use the model to predict the next Close_delta (scaled)\n",
        "    predicted_close_delta_scaled = model.predict(last_window_scaled)\n",
        "\n",
        "    # Step 4: Inverse transform the prediction to get the original scale of Close_delta\n",
        "    predicted_close_delta = scaler_y.inverse_transform(predicted_close_delta_scaled)\n",
        "\n",
        "    predicted_close_delta = predicted_close_delta[0][0]  # Return the predicted value\n",
        "\n",
        "    # Decision logic: Buy if positive, Sell if negative\n",
        "    result = (\n",
        "                f\"Predicted Close increase for {ticker} tomorrow is {(predicted_close_delta * 100):.2f}%. Suggestion: BUY with {percentage_match :.2f}% confidence\"\n",
        "                if predicted_close_delta > 0\n",
        "                else f\"Predicted Close decrease for {ticker} tomorrow is {(predicted_close_delta * 100):.2f}%. Suggestion: SELL with {percentage_match :.2f}% confidence\")\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc_MkMaXdN-4"
      },
      "outputs": [],
      "source": [
        "#stock_pipeline('AAPL')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jixO_2GLdN-7"
      },
      "source": [
        "**Sentiment Analysis Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0z5IoCTdN-9"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVg27OmKdN--",
        "outputId": "b869fc29-9b58-461f-8040-77693338b908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize the sentiment analysis pipeline from Hugging Face\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\",model=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piYctOYUdN-_"
      },
      "outputs": [],
      "source": [
        "# Function to fetch recent stock-related news using yfinance\n",
        "def fetch_stock_news(stock_symbol, num_articles=5):\n",
        "    stock = yf.Ticker(stock_symbol)\n",
        "    news = stock.news  # Get stock news\n",
        "\n",
        "    if not news:\n",
        "        return []  # Return an empty list if no news is available\n",
        "\n",
        "\n",
        "\n",
        "    #Change num_articles to int for Gradio use\n",
        "\n",
        "    num_articles = int(num_articles)\n",
        "    # Extract top `num_articles` news articles\n",
        "    news_headlines = [article['title'] for article in news[:num_articles]]\n",
        "    return news_headlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGaxdhxBdN_A"
      },
      "outputs": [],
      "source": [
        "# Perform sentiment analysis on stock news headlines\n",
        "def analyze_sentiment_on_news(stock_symbol, num_articles):\n",
        "    # Fetch stock news\n",
        "    headlines = fetch_stock_news(stock_symbol, num_articles)\n",
        "\n",
        "    # Check if headlines are available\n",
        "    if not headlines:\n",
        "        print(f\"No news found for {stock_symbol}\")\n",
        "        return\n",
        "\n",
        "    #print(f\"News headlines for {stock_symbol}:\\n\")\n",
        "\n",
        "    # Perform sentiment analysis on each headline\n",
        "    results = sentiment_analysis(headlines)\n",
        "\n",
        "    # Initialize lists to store sentiment and scores\n",
        "    sentiments = []\n",
        "    scores = []\n",
        "\n",
        "    for result in results:\n",
        "        score = result['score']\n",
        "        scores.append(score)\n",
        "        sentiment = result['label']\n",
        "        if sentiment == 'POSITIVE':\n",
        "            sentiments.append(1)\n",
        "        elif sentiment == 'NEGATIVE':\n",
        "            sentiments.append(-1)\n",
        "        else:\n",
        "            sentiments.append(0)\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate the average sentiment score\n",
        "    average_sentiment = np.mean(sentiments)\n",
        "\n",
        "    # Determine overall sentiment\n",
        "    if average_sentiment > 0:\n",
        "      overall_sentiment = \"Positive\"\n",
        "    elif average_sentiment < 0:\n",
        "      overall_sentiment = \"Negative\"\n",
        "    else:\n",
        "      overall_sentiment = \"Neutral\"\n",
        "\n",
        "      # Create a function that averages scores\n",
        "    def average(numbers):\n",
        "     sum_of_numbers = sum(numbers)\n",
        "     average = (sum_of_numbers / len(numbers)) * 100\n",
        "     return average\n",
        "\n",
        "    #Run average function\n",
        "    score_average = average(scores)\n",
        "\n",
        "\n",
        "    #Return the average score and overall sentiment for the stock ticker\n",
        "    return f\"{score_average:.2f}% | {overall_sentiment}\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aec4AbatdN_B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f0fffd67-6e5d-4451-f06d-45d64ecdd562"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'99.15% | Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        " # Example: Analyze sentiment on Apple (AAPL) stock news\n",
        "stock_symbol = \"AAPL\"\n",
        "num_articles = 5\n",
        "analyze_sentiment_on_news(stock_symbol, num_articles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odCHtNPndN_H"
      },
      "source": [
        "**Combined Pipelines**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62B--GpHdN_I"
      },
      "outputs": [],
      "source": [
        "def combined_pipelines(ticker, num_articles=None):\n",
        "  prediction_one = stock_pipeline(ticker)\n",
        "  if num_articles:\n",
        "    prediction_two = analyze_sentiment_on_news(ticker,num_articles)\n",
        "  else:\n",
        "    prediction_two = analyze_sentiment_on_news(ticker,5)\n",
        "  return prediction_one, prediction_two"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLM_r7YTdN_I"
      },
      "source": [
        "**Gradio Interface**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBSsdm5jdN_J",
        "outputId": "a7acf01a-2383-4f17-b1f8-46c4bb90fea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.4.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.4)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.4.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.4.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.1)\n",
            "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.2)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://4b2e67a3fc1c4be92a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4b2e67a3fc1c4be92a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for AAPL from 2021-01-01 to 2024-10-31\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Price                      Date   Adj Close       Close        High  \\\n",
              "0     2021-01-04 00:00:00+00:00  126.683434  129.410004  133.610001   \n",
              "1     2021-01-05 00:00:00+00:00  128.249756  131.009995  131.740005   \n",
              "2     2021-01-06 00:00:00+00:00  123.932648  126.599998  131.050003   \n",
              "3     2021-01-07 00:00:00+00:00  128.161652  130.919998  131.630005   \n",
              "4     2021-01-08 00:00:00+00:00  129.267822  132.050003  132.630005   \n",
              "\n",
              "Price         Low        Open     Volume  \n",
              "0      126.760002  133.520004  143301900  \n",
              "1      128.429993  128.889999   97664900  \n",
              "2      126.379997  127.720001  155088000  \n",
              "3      127.860001  128.360001  109578200  \n",
              "4      130.229996  132.429993  105158200  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6df736f0-5d94-49c8-9dc9-0d4eea5290ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Price</th>\n",
              "      <th>Date</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00+00:00</td>\n",
              "      <td>126.683434</td>\n",
              "      <td>129.410004</td>\n",
              "      <td>133.610001</td>\n",
              "      <td>126.760002</td>\n",
              "      <td>133.520004</td>\n",
              "      <td>143301900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00+00:00</td>\n",
              "      <td>128.249756</td>\n",
              "      <td>131.009995</td>\n",
              "      <td>131.740005</td>\n",
              "      <td>128.429993</td>\n",
              "      <td>128.889999</td>\n",
              "      <td>97664900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00+00:00</td>\n",
              "      <td>123.932648</td>\n",
              "      <td>126.599998</td>\n",
              "      <td>131.050003</td>\n",
              "      <td>126.379997</td>\n",
              "      <td>127.720001</td>\n",
              "      <td>155088000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00+00:00</td>\n",
              "      <td>128.161652</td>\n",
              "      <td>130.919998</td>\n",
              "      <td>131.630005</td>\n",
              "      <td>127.860001</td>\n",
              "      <td>128.360001</td>\n",
              "      <td>109578200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00+00:00</td>\n",
              "      <td>129.267822</td>\n",
              "      <td>132.050003</td>\n",
              "      <td>132.630005</td>\n",
              "      <td>130.229996</td>\n",
              "      <td>132.429993</td>\n",
              "      <td>105158200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6df736f0-5d94-49c8-9dc9-0d4eea5290ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6df736f0-5d94-49c8-9dc9-0d4eea5290ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6df736f0-5d94-49c8-9dc9-0d4eea5290ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-126bf894-f917-484a-9689-e492c09831d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-126bf894-f917-484a-9689-e492c09831d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-126bf894-f917-484a-9689-e492c09831d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"interface\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2021-01-04 00:00:00+00:00\",\n        \"max\": \"2021-01-08 00:00:00+00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2021-01-05 00:00:00+00:00\",\n          \"2021-01-08 00:00:00+00:00\",\n          \"2021-01-06 00:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0753096352137477,\n        \"min\": 123.93264770507812,\n        \"max\": 129.267822265625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          128.249755859375,\n          129.267822265625,\n          123.93264770507812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1199695807413867,\n        \"min\": 126.5999984741211,\n        \"max\": 132.0500030517578,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          131.00999450683594,\n          132.0500030517578,\n          126.5999984741211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0011082427125615,\n        \"min\": 131.0500030517578,\n        \"max\": 133.61000061035156,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          131.74000549316406,\n          132.6300048828125,\n          131.0500030517578\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5261271653339474,\n        \"min\": 126.37999725341797,\n        \"max\": 130.22999572753906,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          128.42999267578125,\n          130.22999572753906,\n          126.37999725341797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6098902727387103,\n        \"min\": 127.72000122070312,\n        \"max\": 133.52000427246094,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          128.88999938964844,\n          132.42999267578125,\n          127.72000122070312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25389987,\n        \"min\": 97664900,\n        \"max\": 155088000,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          97664900,\n          105158200,\n          155088000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Price                      Date       Close        High         Low  \\\n",
              "1     2021-01-05 00:00:00+00:00  131.009995  131.740005  128.429993   \n",
              "2     2021-01-06 00:00:00+00:00  126.599998  131.050003  126.379997   \n",
              "3     2021-01-07 00:00:00+00:00  130.919998  131.630005  127.860001   \n",
              "4     2021-01-08 00:00:00+00:00  132.050003  132.630005  130.229996   \n",
              "5     2021-01-11 00:00:00+00:00  128.979996  130.169998  128.500000   \n",
              "\n",
              "Price        Open     Volume  Open_delta  High_delta  Low_delta  Close_delta  \\\n",
              "1      128.889999   97664900     -0.0347     -0.0140     0.0132       0.0124   \n",
              "2      127.720001  155088000     -0.0091     -0.0052    -0.0160      -0.0337   \n",
              "3      128.360001  109578200      0.0050      0.0044     0.0117       0.0341   \n",
              "4      132.429993  105158200      0.0317      0.0076     0.0185       0.0086   \n",
              "5      129.190002  100384500     -0.0245     -0.0185    -0.0133      -0.0232   \n",
              "\n",
              "Price  Volume_delta  \n",
              "1           -0.3185  \n",
              "2            0.5880  \n",
              "3           -0.2934  \n",
              "4           -0.0403  \n",
              "5           -0.0454  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71b79812-d0af-4b70-b148-80fa5605e27e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Price</th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open_delta</th>\n",
              "      <th>High_delta</th>\n",
              "      <th>Low_delta</th>\n",
              "      <th>Close_delta</th>\n",
              "      <th>Volume_delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00+00:00</td>\n",
              "      <td>131.009995</td>\n",
              "      <td>131.740005</td>\n",
              "      <td>128.429993</td>\n",
              "      <td>128.889999</td>\n",
              "      <td>97664900</td>\n",
              "      <td>-0.0347</td>\n",
              "      <td>-0.0140</td>\n",
              "      <td>0.0132</td>\n",
              "      <td>0.0124</td>\n",
              "      <td>-0.3185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00+00:00</td>\n",
              "      <td>126.599998</td>\n",
              "      <td>131.050003</td>\n",
              "      <td>126.379997</td>\n",
              "      <td>127.720001</td>\n",
              "      <td>155088000</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0052</td>\n",
              "      <td>-0.0160</td>\n",
              "      <td>-0.0337</td>\n",
              "      <td>0.5880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00+00:00</td>\n",
              "      <td>130.919998</td>\n",
              "      <td>131.630005</td>\n",
              "      <td>127.860001</td>\n",
              "      <td>128.360001</td>\n",
              "      <td>109578200</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0.0341</td>\n",
              "      <td>-0.2934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00+00:00</td>\n",
              "      <td>132.050003</td>\n",
              "      <td>132.630005</td>\n",
              "      <td>130.229996</td>\n",
              "      <td>132.429993</td>\n",
              "      <td>105158200</td>\n",
              "      <td>0.0317</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0185</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>-0.0403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-01-11 00:00:00+00:00</td>\n",
              "      <td>128.979996</td>\n",
              "      <td>130.169998</td>\n",
              "      <td>128.500000</td>\n",
              "      <td>129.190002</td>\n",
              "      <td>100384500</td>\n",
              "      <td>-0.0245</td>\n",
              "      <td>-0.0185</td>\n",
              "      <td>-0.0133</td>\n",
              "      <td>-0.0232</td>\n",
              "      <td>-0.0454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71b79812-d0af-4b70-b148-80fa5605e27e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71b79812-d0af-4b70-b148-80fa5605e27e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71b79812-d0af-4b70-b148-80fa5605e27e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-50fb8e35-1d20-48ae-b80d-3a1b1209971f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50fb8e35-1d20-48ae-b80d-3a1b1209971f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-50fb8e35-1d20-48ae-b80d-3a1b1209971f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"interface\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2021-01-05 00:00:00+00:00\",\n        \"max\": \"2021-01-11 00:00:00+00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2021-01-06 00:00:00+00:00\",\n          \"2021-01-11 00:00:00+00:00\",\n          \"2021-01-07 00:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1581644611946325,\n        \"min\": 126.5999984741211,\n        \"max\": 132.0500030517578,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          126.5999984741211,\n          128.97999572753906,\n          130.9199981689453\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9092770357774662,\n        \"min\": 130.1699981689453,\n        \"max\": 132.6300048828125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          131.0500030517578,\n          130.1699981689453,\n          131.6300048828125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3838163773144923,\n        \"min\": 126.37999725341797,\n        \"max\": 130.22999572753906,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          126.37999725341797,\n          128.5,\n          127.86000061035156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.827254035484791,\n        \"min\": 127.72000122070312,\n        \"max\": 132.42999267578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          127.72000122070312,\n          129.19000244140625,\n          128.36000061035156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23649876,\n        \"min\": 97664900,\n        \"max\": 155088000,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          155088000,\n          100384500,\n          109578200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026063998158379308,\n        \"min\": -0.0347,\n        \"max\": 0.0317,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0091,\n          -0.0245,\n          0.005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011295043160608108,\n        \"min\": -0.0185,\n        \"max\": 0.0076,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0052,\n          -0.0185,\n          0.0044\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016174887943970432,\n        \"min\": -0.016,\n        \"max\": 0.0185,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.016,\n          -0.0133,\n          0.0117\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027675855903657252,\n        \"min\": -0.0337,\n        \"max\": 0.0341,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0337,\n          -0.0232,\n          0.0341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36556553037724987,\n        \"min\": -0.3185,\n        \"max\": 0.588,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.588,\n          -0.0454,\n          -0.2934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Price  Open_delta  High_delta  Low_delta  Close_delta  Volume_delta\n",
              "1         -0.0347     -0.0140     0.0132       0.0124       -0.3185\n",
              "2         -0.0091     -0.0052    -0.0160      -0.0337        0.5880\n",
              "3          0.0050      0.0044     0.0117       0.0341       -0.2934\n",
              "4          0.0317      0.0076     0.0185       0.0086       -0.0403\n",
              "5         -0.0245     -0.0185    -0.0133      -0.0232       -0.0454"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-007a278d-2e9b-4b8f-8b14-789e8d648ffe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Price</th>\n",
              "      <th>Open_delta</th>\n",
              "      <th>High_delta</th>\n",
              "      <th>Low_delta</th>\n",
              "      <th>Close_delta</th>\n",
              "      <th>Volume_delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.0347</td>\n",
              "      <td>-0.0140</td>\n",
              "      <td>0.0132</td>\n",
              "      <td>0.0124</td>\n",
              "      <td>-0.3185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0052</td>\n",
              "      <td>-0.0160</td>\n",
              "      <td>-0.0337</td>\n",
              "      <td>0.5880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0.0341</td>\n",
              "      <td>-0.2934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0317</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0185</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>-0.0403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.0245</td>\n",
              "      <td>-0.0185</td>\n",
              "      <td>-0.0133</td>\n",
              "      <td>-0.0232</td>\n",
              "      <td>-0.0454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-007a278d-2e9b-4b8f-8b14-789e8d648ffe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-007a278d-2e9b-4b8f-8b14-789e8d648ffe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-007a278d-2e9b-4b8f-8b14-789e8d648ffe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d25639b2-c1cd-4624-a9e5-b99ad1c1693b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d25639b2-c1cd-4624-a9e5-b99ad1c1693b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d25639b2-c1cd-4624-a9e5-b99ad1c1693b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"interface\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Open_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026063998158379308,\n        \"min\": -0.0347,\n        \"max\": 0.0317,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0091,\n          -0.0245,\n          0.005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011295043160608108,\n        \"min\": -0.0185,\n        \"max\": 0.0076,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0052,\n          -0.0185,\n          0.0044\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016174887943970432,\n        \"min\": -0.016,\n        \"max\": 0.0185,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.016,\n          -0.0133,\n          0.0117\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027675855903657252,\n        \"min\": -0.0337,\n        \"max\": 0.0341,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0337,\n          -0.0232,\n          0.0341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36556553037724987,\n        \"min\": -0.3185,\n        \"max\": 0.588,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.588,\n          -0.0454,\n          -0.2934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 entries of X:\n",
            " [[[-3.470e-02 -1.400e-02  1.320e-02  1.240e-02 -3.185e-01]\n",
            "  [-9.100e-03 -5.200e-03 -1.600e-02 -3.370e-02  5.880e-01]\n",
            "  [ 5.000e-03  4.400e-03  1.170e-02  3.410e-02 -2.934e-01]\n",
            "  ...\n",
            "  [ 1.440e-02  3.000e-03  3.000e-03 -1.600e-03  1.413e-01]\n",
            "  [-6.700e-03 -7.200e-03  8.000e-04 -4.000e-04 -2.143e-01]\n",
            "  [-4.100e-03  2.000e-03 -1.060e-02 -1.240e-02  6.725e-01]]\n",
            "\n",
            " [[-9.100e-03 -5.200e-03 -1.600e-02 -3.370e-02  5.880e-01]\n",
            "  [ 5.000e-03  4.400e-03  1.170e-02  3.410e-02 -2.934e-01]\n",
            "  [ 3.170e-02  7.600e-03  1.850e-02  8.600e-03 -4.030e-02]\n",
            "  ...\n",
            "  [-6.700e-03 -7.200e-03  8.000e-04 -4.000e-04 -2.143e-01]\n",
            "  [-4.100e-03  2.000e-03 -1.060e-02 -1.240e-02  6.725e-01]\n",
            "  [-6.900e-03 -1.440e-02 -4.200e-03 -5.300e-03 -2.464e-01]]\n",
            "\n",
            " [[ 5.000e-03  4.400e-03  1.170e-02  3.410e-02 -2.934e-01]\n",
            "  [ 3.170e-02  7.600e-03  1.850e-02  8.600e-03 -4.030e-02]\n",
            "  [-2.450e-02 -1.850e-02 -1.330e-02 -2.320e-02 -4.540e-02]\n",
            "  ...\n",
            "  [-4.100e-03  2.000e-03 -1.060e-02 -1.240e-02  6.725e-01]\n",
            "  [-6.900e-03 -1.440e-02 -4.200e-03 -5.300e-03 -2.464e-01]\n",
            "  [-3.900e-03 -3.600e-03 -4.900e-03 -2.600e-03 -5.150e-02]]\n",
            "\n",
            " [[ 3.170e-02  7.600e-03  1.850e-02  8.600e-03 -4.030e-02]\n",
            "  [-2.450e-02 -1.850e-02 -1.330e-02 -2.320e-02 -4.540e-02]\n",
            "  [-5.300e-03 -3.700e-03 -1.280e-02 -1.400e-03 -8.400e-02]\n",
            "  ...\n",
            "  [-6.900e-03 -1.440e-02 -4.200e-03 -5.300e-03 -2.464e-01]\n",
            "  [-3.900e-03 -3.600e-03 -4.900e-03 -2.600e-03 -5.150e-02]\n",
            "  [-6.400e-03 -9.000e-04  9.000e-04  6.300e-03 -1.236e-01]]\n",
            "\n",
            " [[-2.450e-02 -1.850e-02 -1.330e-02 -2.320e-02 -4.540e-02]\n",
            "  [-5.300e-03 -3.700e-03 -1.280e-02 -1.400e-03 -8.400e-02]\n",
            "  [ 2.000e-03  1.360e-02  1.280e-02  1.620e-02 -3.600e-02]\n",
            "  ...\n",
            "  [-3.900e-03 -3.600e-03 -4.900e-03 -2.600e-03 -5.150e-02]\n",
            "  [-6.400e-03 -9.000e-04  9.000e-04  6.300e-03 -1.236e-01]\n",
            "  [ 3.200e-03 -3.100e-03 -7.400e-03 -1.220e-02  2.859e-01]]]\n",
            "First 5 entries of y:\n",
            " [-0.0053 -0.0026  0.0063 -0.0122  0.019 ]\n",
            "X_train shape: (689, 100, 5)\n",
            "X_test shape: (173, 100, 5)\n",
            "y_train shape: (689,)\n",
            "y_test shape: (173,)\n",
            "Epoch 1/70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 - 11s - 426ms/step - loss: 0.1933 - val_loss: 0.1841\n",
            "Epoch 2/70\n",
            "25/25 - 8s - 323ms/step - loss: 0.1862 - val_loss: 0.1770\n",
            "Epoch 3/70\n",
            "25/25 - 5s - 216ms/step - loss: 0.1793 - val_loss: 0.1704\n",
            "Epoch 4/70\n",
            "25/25 - 8s - 337ms/step - loss: 0.1727 - val_loss: 0.1640\n",
            "Epoch 5/70\n",
            "25/25 - 6s - 250ms/step - loss: 0.1663 - val_loss: 0.1576\n",
            "Epoch 6/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.1598 - val_loss: 0.1512\n",
            "Epoch 7/70\n",
            "25/25 - 5s - 218ms/step - loss: 0.1536 - val_loss: 0.1453\n",
            "Epoch 8/70\n",
            "25/25 - 6s - 256ms/step - loss: 0.1476 - val_loss: 0.1391\n",
            "Epoch 9/70\n",
            "25/25 - 10s - 418ms/step - loss: 0.1413 - val_loss: 0.1329\n",
            "Epoch 10/70\n",
            "25/25 - 8s - 332ms/step - loss: 0.1349 - val_loss: 0.1263\n",
            "Epoch 11/70\n",
            "25/25 - 5s - 200ms/step - loss: 0.1280 - val_loss: 0.1193\n",
            "Epoch 12/70\n",
            "25/25 - 4s - 155ms/step - loss: 0.1208 - val_loss: 0.1120\n",
            "Epoch 13/70\n",
            "25/25 - 5s - 193ms/step - loss: 0.1136 - val_loss: 0.1053\n",
            "Epoch 14/70\n",
            "25/25 - 8s - 318ms/step - loss: 0.1068 - val_loss: 0.0981\n",
            "Epoch 15/70\n",
            "25/25 - 7s - 295ms/step - loss: 0.0991 - val_loss: 0.0901\n",
            "Epoch 16/70\n",
            "25/25 - 5s - 201ms/step - loss: 0.0907 - val_loss: 0.0815\n",
            "Epoch 17/70\n",
            "25/25 - 5s - 184ms/step - loss: 0.0819 - val_loss: 0.0726\n",
            "Epoch 18/70\n",
            "25/25 - 4s - 178ms/step - loss: 0.0726 - val_loss: 0.0634\n",
            "Epoch 19/70\n",
            "25/25 - 5s - 202ms/step - loss: 0.0630 - val_loss: 0.0536\n",
            "Epoch 20/70\n",
            "25/25 - 4s - 153ms/step - loss: 0.0529 - val_loss: 0.0434\n",
            "Epoch 21/70\n",
            "25/25 - 5s - 198ms/step - loss: 0.0425 - val_loss: 0.0333\n",
            "Epoch 22/70\n",
            "25/25 - 7s - 270ms/step - loss: 0.0325 - val_loss: 0.0241\n",
            "Epoch 23/70\n",
            "25/25 - 9s - 345ms/step - loss: 0.0240 - val_loss: 0.0171\n",
            "Epoch 24/70\n",
            "25/25 - 6s - 238ms/step - loss: 0.0180 - val_loss: 0.0130\n",
            "Epoch 25/70\n",
            "25/25 - 4s - 168ms/step - loss: 0.0150 - val_loss: 0.0113\n",
            "Epoch 26/70\n",
            "25/25 - 6s - 248ms/step - loss: 0.0140 - val_loss: 0.0110\n",
            "Epoch 27/70\n",
            "25/25 - 4s - 171ms/step - loss: 0.0139 - val_loss: 0.0110\n",
            "Epoch 28/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 29/70\n",
            "25/25 - 6s - 237ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 30/70\n",
            "25/25 - 5s - 184ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 31/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 32/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 33/70\n",
            "25/25 - 6s - 221ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 34/70\n",
            "25/25 - 8s - 331ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 35/70\n",
            "25/25 - 7s - 274ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 36/70\n",
            "25/25 - 9s - 340ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 37/70\n",
            "25/25 - 5s - 220ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 38/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 39/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 40/70\n",
            "25/25 - 4s - 179ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 41/70\n",
            "25/25 - 4s - 174ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 42/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 43/70\n",
            "25/25 - 7s - 264ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 44/70\n",
            "25/25 - 9s - 349ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 45/70\n",
            "25/25 - 4s - 167ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 46/70\n",
            "25/25 - 5s - 192ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 47/70\n",
            "25/25 - 5s - 194ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 48/70\n",
            "25/25 - 7s - 281ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 49/70\n",
            "25/25 - 4s - 146ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 50/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 51/70\n",
            "25/25 - 7s - 279ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 52/70\n",
            "25/25 - 4s - 145ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 53/70\n",
            "25/25 - 5s - 202ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 54/70\n",
            "25/25 - 5s - 205ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 55/70\n",
            "25/25 - 9s - 346ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 56/70\n",
            "25/25 - 7s - 283ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 57/70\n",
            "25/25 - 8s - 329ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 58/70\n",
            "25/25 - 7s - 266ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 59/70\n",
            "25/25 - 4s - 144ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 60/70\n",
            "25/25 - 5s - 204ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 61/70\n",
            "25/25 - 6s - 229ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 62/70\n",
            "25/25 - 4s - 145ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 63/70\n",
            "25/25 - 4s - 143ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 64/70\n",
            "25/25 - 6s - 223ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 65/70\n",
            "25/25 - 8s - 329ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 66/70\n",
            "25/25 - 7s - 263ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 67/70\n",
            "25/25 - 4s - 143ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 68/70\n",
            "25/25 - 5s - 208ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 69/70\n",
            "25/25 - 6s - 223ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 70/70\n",
            "25/25 - 4s - 143ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step\n",
            "First 5 entries of y_pred_scaled [[0.38916534]\n",
            " [0.3988261 ]\n",
            " [0.40590477]\n",
            " [0.39574352]\n",
            " [0.40688267]]\n",
            "First 5 entries of y_pred_original [[-0.00122028]\n",
            " [ 0.00020661]\n",
            " [ 0.00125213]\n",
            " [-0.00024868]\n",
            " [ 0.00139657]]\n",
            "First 5 entries of y_test_scaled [[0.42992552]\n",
            " [0.41435342]\n",
            " [0.50914015]\n",
            " [0.422478  ]\n",
            " [0.72647258]]\n",
            "First 5 entries of y_test_original [[0.0048]\n",
            " [0.0025]\n",
            " [0.0165]\n",
            " [0.0037]\n",
            " [0.0486]]\n",
            "Mean Squared Error (MSE): 0.000240\n",
            "Root Mean Squared Error (RMSE): 0.015504\n",
            "Mean Absolute Error (MAE): 0.011623\n",
            "R-squared (R²): 0.003134\n",
            "0     False\n",
            "1      True\n",
            "2      True\n",
            "3     False\n",
            "4      True\n",
            "      ...  \n",
            "95    False\n",
            "96     True\n",
            "97    False\n",
            "98    False\n",
            "99     True\n",
            "Length: 100, dtype: bool\n",
            "Percentage of Sign Matches: 53.76%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://4b2e67a3fc1c4be92a.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#If gradio not installed, unhash install gradio below and rerun code\n",
        "\n",
        "#!pip install gradio\n",
        "import gradio as gr\n",
        "\n",
        "input_component_one = gr.Textbox(label=\"Stock Ticker\")\n",
        "input_component_two = gr.Textbox(label=\"Number of articles\")\n",
        "output_component_one = gr.Textbox(label=\"Stock Price Prediction\")\n",
        "output_component_two = gr.Textbox(label=\"Public Sentiment Score \")\n",
        "\n",
        "output_component = [output_component_one, output_component_two]\n",
        "\n",
        "interface = gr.Interface(fn= combined_pipelines, inputs=[input_component_one,input_component_two], outputs=[output_component_one, output_component_two])\n",
        "interface.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "RyanDev2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}