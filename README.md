# Introduction:
This project is being developed as part of the final requirement for the SMU AI Bootcamp, with the aim of achieving a Certificate in AI from Southern Methodist University. It serves as a comprehensive demonstration of the knowledge acquired throughout the course, applying theoretical and practical AI concepts to a real-world scenario. We have chosen a stock prediction project due to the abundance and quality of time-series data available in the financial markets. The goal of this project is to create a stock prediction engine that can autonomously collect relevant stock market data, clean and preprocess it, train a predictive model, and provide signals that indicate opportunities to buy or sell specific stocks.

# Premise:
The effectiveness of this project is based on several key principles of financial markets and machine learning.
First, we ascribe to the principle that prices in a liquid market are generally at equilibrium. This means that, in a well-functioning market, prices reflect all available information, and any changes in supply or demand are quickly incorporated into the price, thereby balancing the forces acting on the market. This principle applies across all types of markets, including stocks, commodities, real estate, foreign exchange, and even cryptocurrency. Each of these markets experiences fluctuations in supply and demand, creating opportunities for profit when imbalances occur. However, we chose to focus on stocks because of the wealth of historical and real-time data that is readily available, which makes it ideal for applying machine learning techniques.
This concept can be compared to a casino's approach, where the odds are slightly in favor of the house. Although individual results may vary, the casino consistently profits over time because of this small advantage. Similarly, our goal is to build a predictive model that performs slightly better than chance, allowing us to realize consistent profits over time by exploiting the small differences between equilibrium prices and market movements.
The equilibrium price is essentially the point where the quantity of an asset demanded by buyers matches the quantity supplied by sellers, minimizing any potential discrepancy and creating stability in the market. In all types of markets, this balance is critical. When imbalances occur, such as an excess of demand over supply or vice versa, prices adjust to reach a new equilibrium. These fluctuations present opportunities for traders to profit by anticipating the direction of the price movement before equilibrium is restored. We chose stocks as the focus of our project primarily due to the abundance of available data, which provides a fertile ground for applying machine learning techniques to detect these opportunities effectively.
A liquid market is one where there are many buyers and sellers, ensuring that trades can be executed quickly without causing significant price changes. The importance of a liquid market lies in its ability to provide stability and minimize transaction costs, as higher liquidity leads to narrower bid-ask spreads. This reduces the cost of buying or selling assets, allowing for more efficient trading and better price discovery, which is crucial for building accurate predictive models. Imbalances in the market, such as discrepancies between supply and demand or mispricing of assets, create opportunities for profit. Traders who can identify these imbalances early are able to capitalize on price movements before the market corrects itself. In such a setting, achieving a model prediction with a probability slightly better than 50% can yield profitability in the long run, provided that transaction fees are managed effectively.

# Approach:
We have designed our project using multiple Jupyter Notebooks to maintain a structured and modular workflow. Each notebook focuses on a specific part of the process, allowing us to address training and prediction tasks in an organized manner without overlap or confusion. By segmenting these tasks, we have greater flexibility to adjust individual components, such as different models or datasets. Additionally, we have developed a set of reusable Python functions stored in a script directory. This approach enables us to reuse logic across different notebooks, ensuring consistency and maintainability. By avoiding redundancy, we reduce the risk of errors and make it easier to make updates that will be applied across all relevant areas of the project.
Using a sliding window approach is crucial when analyzing time series data, as it allows models to capture temporal dependencies and patterns that are inherent in the data. A sliding window is a technique where a fixed-length subset of the time series is moved sequentially over the data, creating overlapping sequences that can be used for training machine learning models. This technique ensures that all parts of the data are included in the analysis and that each observation is contextualized within its preceding and succeeding values, thereby preserving the sequential nature of the dataset. By maintaining these relationships, sliding windows help models learn the continuity and trends in time series, which are critical for making accurate predictions.
One of the major risks in analyzing time series data without considering temporal continuity is the inadvertent destruction of the sequence by randomly removing rows from the middle of the dataset. Unlike non-temporal datasets, where a random sample may still retain the essential characteristics of the data, time series data is highly dependent on the order of observations. Removing rows disrupts the flow of information, effectively breaking the sequence and eliminating any patterns or trends that exist over time. This is particularly problematic for predictive modeling, as the model loses the ability to understand how past observations influence future values, which is the foundation of time series forecasting.
The sliding window method mitigates this risk by ensuring that all observations are treated within their original temporal context. Instead of randomly sampling data points, sliding windows provide overlapping snapshots of the series, where each window contains a complete segment of sequential data. This approach allows models to effectively learn from both short-term fluctuations and long-term trends in the data. By maintaining the integrity of the time series, sliding windows help ensure that the predictive power of the model is maximized, allowing it to make informed predictions that are grounded in the temporal relationships inherent in the data.


# Summary Flow:
Each of our Jupyter Notebooks uses the following process flow and uses a different model and parameters to find the best prediction scenario.  The Jupyter Notebooks begin by setting up the environment and importing necessary libraries, including system, logging, data analysis, and machine learning packages like TensorFlow and PyTorch. The notebooks then prompt the user for a stock ticker and defines a date range to fetch stock market data using a custom function. Once the data is fetched, it is transformed by calculating delta values for key columns like Open, High, Low, Close, and Volume, while excluding certain columns from calculations.
The transformed data is prepared for model training by generating sliding window time series sequences and splitting the data into training and testing sets. The values are then scaled using MinMaxScaler to normalize the input and output data for better model performance.
An model then is constructed using the training and testing data, with parameters like the number of layers, units per layer, and training configurations such as learning rate, epochs, and batch size. After training, the model is used to make predictions on the test set, and the predictions are scaled back to their original units.
The notebooks evaluate the model's performance using metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared (R²). A comparison DataFrame is created to compare the actual and predicted values, calculate the differences, and evaluate the accuracy by checking the percentage of matching signs between the actual and predicted values.
Finally, the notebooks predict the change in the closing price (`Close_delta`) for the next day using the trained model. It extracts the most recent data as input, scales it for the model, and then uses the model to make a prediction. The predicted value is then transformed back to the original scale. Then, a decision is made.  If the predicted `Close_delta` is positive, a "buy" suggestion is printed; if negative, a "sell" suggestion is made, along with a confidence percentage.

**Python Functions:**
The following Python functions were created to reduce the amount of duplicate code throughout the Jupyter Notebooks.
•	create_time_series_windows
•	prepare_data_for_training_with_windows
•	fetch_stock_data
•	gru_model
•	train_gru_model
•	lstm_model
•	prepare_sliding_window_data
•	prepare_data_for_training
•	transform_stock_data_to_delta
•	transform_with_history

# Functions
1. **create_time_series_windows**
   
The function `create_time_series_windows` is used to generate time series data windows for training machine learning models, specifically for time series prediction. It takes a dataset, the target column to predict, and the desired length of the time windows (number of timesteps) as inputs. The function's purpose is to prepare the data in such a way that each sequence of features (denoted as `X`) corresponds to a target value (`y`) representing the next value in the sequence.
The function iterates over the dataset to create sliding windows of input features and corresponding targets. For each iteration, it extracts a sequence of data (`X_window`) of length `n_timesteps` and selects the next value of the target column (`y_window`). These sequences and their associated next values form the input-output pairs used for training the predictive model. By creating these sliding windows, the model can learn from past sequences to forecast future values, making it ideal for applications like stock market prediction, where historical data is used to anticipate future price movements.
The key to the function's effectiveness lies in its ability to generate overlapping input sequences that retain the time-dependent relationship between features. This type of data preparation is particularly suitable for models such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, which excel at capturing sequential patterns. By including the target column (`Close_delta`) in each input sequence while shifting the target value to the subsequent timestep, the function ensures that the model can leverage all available information to make accurate future predictions.

2. **prepare_data_for_training_with_windows**
   
The function prepare_data_for_training_with_windows is used to prepare the transformed data for training by creating time series windows and splitting the data into training and testing sets. The function takes as inputs the transformed DataFrame containing historical data, the target column to predict, and the number of timesteps for each window. It first generates sliding windows of features (X) and target values (y) using the create_time_series_windows function, ensuring that the time-dependent relationships are preserved. After creating these windows, the function splits the data into training and testing sets using an 80/20 ratio, with random shuffling applied for robust model training and evaluation.
The main purpose of this function is to ensure that the data is properly structured and divided for model training and testing, allowing for effective learning and validation. By splitting the data into training and testing sets, the model can learn from one portion of the data while being evaluated on unseen data, which helps in understanding the generalizability of the model. This approach is particularly valuable in time series prediction, where patterns learned from past sequences are used to predict future values. The function helps streamline the data preparation process, making it easier to create models that can accurately forecast stock price movements.

3. **fetch_stock_data**
   
The function fetch_stock_data is used to retrieve historical stock data for a specified ticker symbol between given dates. It takes in the stock ticker, start date, and optionally an end date as inputs. If the end date is not provided, it defaults to the current date, ensuring that data is always available up to the latest point in time. The function uses the yfinance library to download the data, handling potential issues like missing data or multi-level column names.
The logic begins by setting up a logger to track the process, providing useful information for debugging and understanding the flow of data retrieval. If no end date is provided, the function sets it to the current date, and the logger records this adjustment. It then proceeds to download the stock data using the specified ticker and date range. If no data is found, the function logs a warning and returns an empty DataFrame to prevent further errors in the workflow.
Once data is retrieved, the function resets the index to make the date a column, allowing easier access and manipulation. If the DataFrame has multi-level column names (e.g., if it includes the ticker symbol in the headers), the function flattens these column names to simplify the dataset, ensuring that it can be easily used for subsequent processing. Finally, the function returns the simplified DataFrame, which can be used for analysis, modeling, or other purposes. The overall process ensures that the data is ready for further use without unnecessary complexity, and potential issues are logged to help in troubleshooting.

3. **gru_model**
   
The function `gru_model` is designed to create, train, and evaluate a Gated Recurrent Unit (GRU) model for time series prediction. It takes as inputs the training and testing datasets, the number of timesteps and features, and the configuration for GRU layers, including the number of layers, units per layer, learning rate, number of epochs, and batch size. The function returns both the predicted values for the test set and the trained model itself.
The logic of the function begins by ensuring the data is properly reshaped for the GRU model. The input data (`X_train` and `X_test`) is reshaped into a 3D structure suitable for time series models: `[samples, timesteps, features]`. This reshaping is essential because GRU models require sequences of data to learn temporal relationships effectively.
Next, the function dynamically constructs the GRU model using the specified number of layers and units per layer. For each layer, if it is not the final one, the function adds a GRU layer configured to return sequences, allowing the subsequent layer to receive sequential information. The last GRU layer, however, is set to not return sequences, as it directly feeds into the output layer. The final layer is a Dense layer with a single unit, representing the predicted value for the target variable.
The model is then compiled using the Adam optimizer with a specified learning rate and mean squared error (MSE) as the loss function. This choice of optimizer and loss function is common for regression problems, where minimizing the MSE helps in achieving more accurate predictions.
The training phase follows, where the model is trained using the provided training data (`X_train`, `y_train`) for a specified number of epochs and batch size. The function also includes validation against the test data (`X_test`, `y_test`) to monitor the model's performance during training. After training, the model is used to predict values for the test set, and these predictions are returned along with the trained model.
This approach allows for flexibility in configuring the GRU model, making it adaptable to different time series prediction problems. By dynamically setting the number of layers, units, and other parameters, the function can be used to experiment with various model architectures to determine the most effective configuration for a given dataset.

4. **train_gru_model**
   
The function `train_gru_model` creates, trains, and evaluates a Gated Recurrent Unit (GRU) model using PyTorch for time series prediction. It takes as inputs the training and testing datasets, the number of timesteps and features, the number of GRU layers, units per layer, learning rate, number of epochs, and batch size. The function returns the predicted values for the test set and the trained model itself.
The function starts by converting the input data (`X_train`, `y_train`, `X_test`, `y_test`) into PyTorch tensors, which are the required format for training models in PyTorch. The GRU model is then initialized using the `GRUModel` class, which is defined to include a GRU layer followed by a fully connected layer. The GRU layer is designed to capture sequential dependencies, while the fully connected layer maps the GRU outputs to the final prediction.
The training process begins by defining a loss function, Mean Squared Error (MSE), which is commonly used for regression tasks, and an optimizer, Adam, which adjusts the model weights to minimize the loss. During each epoch of training, the model performs a forward pass to compute predictions, calculates the loss, and then performs a backward pass to update the weights based on the computed gradients.
After training, the model is evaluated on the test data. During this phase, the model's predictions are compared to the actual test targets, and the loss is calculated to assess the model's performance. The function returns the predicted values for the test set as well as the trained model, providing a complete pipeline from model creation to evaluation.
The logic behind the function is designed to ensure that the GRU model effectively learns from the sequential nature of the time series data. The use of multiple GRU layers allows the model to capture complex temporal patterns, while the fully connected layer ensures that the learned features are mapped to the desired output. By using PyTorch, the function provides flexibility in model training and offers robust tools for optimizing performance, making it suitable for a wide range of time series prediction tasks.

5. **lstm_model**
   
The function `lstm_model` creates, trains, and evaluates a Long Short-Term Memory (LSTM) model for time series prediction using TensorFlow and Keras. It takes as inputs the training and testing datasets, the number of timesteps and features, the number of LSTM layers, units per layer, learning rate, number of epochs, and batch size. The function returns the predicted values for the test set and the trained LSTM model.
The function begins by reshaping the input data (`X_train` and `X_test`) into a 3D format, which is essential for LSTM models: `[samples, timesteps, features]`. This reshaping allows the model to process sequential data effectively, learning from the temporal dependencies in the dataset.
Next, the function constructs the LSTM model using the Keras `Sequential` API. It dynamically adds the LSTM layers based on the specified number of layers (`num_layers`) and units per layer (`units_per_layer`). If the layer is not the final one, it is configured to return sequences, ensuring that subsequent LSTM layers can receive sequential information. The final LSTM layer does not return sequences, as it directly feeds into the output layer. The output layer is a fully connected Dense layer with a single unit, representing the predicted value.
The model is then compiled using the Adam optimizer with a specified learning rate and the mean squared error (MSE) loss function. The choice of MSE is common for regression tasks, where minimizing this loss helps achieve more accurate predictions. The Adam optimizer is used to adjust model weights efficiently during training.
The training phase involves fitting the model to the training data (`X_train`, `y_train`) for a specified number of epochs and batch size. The validation data (`X_test`, `y_test`) is also provided to monitor model performance during training. After training, the model is used to predict values for the test set, and these predictions are returned along with the trained model.
The function's logic is designed to ensure that the LSTM model effectively learns from time series data by capturing long-term dependencies through its gated architecture. By allowing the user to configure the number of layers, units, learning rate, and other parameters, the function provides flexibility for optimizing the model to suit different time series prediction tasks. The use of multiple LSTM layers enables the model to capture complex patterns in sequential data, making it suitable for applications such as stock market prediction.

6. **prepare_sliding_window_data**
   
The function `prepare_sliding_window_data` processes a given DataFrame by removing unnecessary columns and retaining only the delta values. The input is a DataFrame containing transformed historical data, and the output is a cleaned DataFrame consisting exclusively of the relevant delta columns.
The function starts by defining a list of columns to drop, which includes 'Date', 'Close', 'High', 'Low', 'Open', and 'Volume'. These columns represent raw data that is not needed for time series prediction, as the focus is on the changes or deltas over time rather than the absolute values. The function then drops these specified columns using the `drop` method, with the `errors='ignore'` parameter to ensure that any columns that might not be present do not cause an error.
The resulting DataFrame contains only the delta values, which are essential for training machine learning models aimed at predicting future changes rather than absolute values. This approach simplifies the dataset, allowing the model to focus solely on the relevant features that capture the changes in the stock's performance over time. By reducing the dataset to only include deltas, the function helps ensure that the model can effectively learn from the temporal patterns and relationships in the data without being influenced by non-essential information.

7. **prepare_data_for_training**
   
The function `prepare_data_for_training` is designed to prepare a given DataFrame for machine learning by cleaning the data and splitting it into training and testing sets. It takes a DataFrame containing transformed historical data as input and outputs separate feature sets (`X`) and target sets (`y`) for both training and testing purposes.
The function begins by dropping the original `High_delta` and `Low_delta` columns, which are not needed for prediction. This step ensures that only the relevant columns remain, simplifying the dataset and focusing on features that are useful for predicting future values. The function then separates the features (`X`) from the target variable (`y`). The target is specifically defined as `Close_delta`, representing the change in the closing price, which is the variable the model aims to predict.
Once the features and target variables are defined, the function splits the dataset into training and testing sets using an 80/20 ratio. This split allows the model to learn from a substantial portion of the data while leaving a smaller portion for evaluating its performance on unseen data. By dividing the data in this way, the function ensures that the machine learning model can be trained effectively and validated for accuracy and generalizability.
The logic of this function helps streamline the preparation of data, which is a crucial step in building reliable machine learning models. By removing unnecessary columns and splitting the data into training and testing sets, it ensures that the model has access to clean, relevant data for learning while also providing a means to evaluate its predictive capabilities.

7. **transform_stock_data_to_delta**
   
The function `transform_stock_data_to_delta` is used to convert stock data into a format that focuses on the proportional changes (deltas) in specified columns. It takes as input a DataFrame containing stock data and allows for the exclusion of specific columns, retaining certain columns without transformation, and calculating the deltas for the remaining columns. The output is a transformed DataFrame that captures the relative changes in stock values over time.
The function begins by optionally dropping columns specified in the `columns_to_exclude` parameter, ensuring that irrelevant data is removed from the analysis. If no columns are provided for exclusion, all columns remain intact for subsequent processing. Next, the function determines which columns will undergo delta calculation. If no specific columns are provided for calculation, the function automatically selects all numeric columns, excluding those specified in `columns_to_keep`. This ensures that only relevant numerical data is transformed, simplifying the dataset.
After identifying the columns for delta calculation, the function creates a copy of the input DataFrame to avoid modifying the original data. It then calculates the delta for each specified column by taking the difference between the current and previous row values and dividing by the previous row's value. This results in a new column for each transformed column, named with a `_delta` suffix, representing the proportional change. The delta values are rounded for readability, making the transformed data easier to interpret.
Finally, the function drops the first row of the transformed DataFrame, as it contains `NaN` values resulting from the calculation of the difference from a non-existent prior row. This cleaned DataFrame is then returned, providing a dataset that highlights the relative changes in stock metrics over time. By focusing on these deltas, the function helps create a dataset that is more informative for machine learning models aimed at predicting future stock movements based on historical trends.

8. **transform_with_history**
   
The function `transform_with_history` is used to add historical context to a given DataFrame containing delta values by appending past values as new columns. The goal is to enhance the dataset by including previous data points for each of the main features, allowing machine learning models to better understand temporal relationships. The function takes as input the transformed DataFrame and the number of historical rows to include, and it returns a DataFrame with the historical deltas appended.
The function starts by selecting a subset of columns from the input DataFrame, which includes 'Date', 'Open_delta', 'High_delta', 'Low_delta', and 'Close_delta'. It checks if these columns are present in the DataFrame, and if any are missing, an error is raised. This step ensures that the required data is available before proceeding with the transformation.
Next, the function appends historical columns using the `shift` method, which creates lagged versions of the delta values for a specified number of previous time steps (`history_length`). For each delta column, the function generates new columns for each lag, named with a suffix indicating the number of periods shifted (e.g., 'Open_delta-1', 'High_delta-2'). This step provides a comprehensive view of past performance, which is valuable for predictive modeling.
After generating the historical columns, the function drops rows that contain `NaN` values, which are introduced by the shifting process. The first few rows will lack historical data for the specified number of periods, so they are removed to ensure that the final DataFrame is complete and ready for use. The resulting DataFrame is then returned, enriched with historical features that help capture time-based patterns and improve the performance of machine learning models in predicting future outcomes.

# Observations:

Randomness in Execution: Since each time we trained our model using a random mix of 80% training and 20% testing data, we receive varying results when we validated the results of the training.  Therefore, we executed a series of tests to find a 
Training Parameters: We adjusted several of the parameters to the Keras and Pytorch models.
Timesteps: We adjusted the number of timesteps to determine the optimal history to consider to provide the most accurate results.  We started with 25 timesteps to represent just over a month of trading days.  From this we adjusted the number of times steps down to 15, 10 , 5 and 2 to make sure we were no overcomplicating the trends.  The lover numbers did not do any better than the original 25 timesteps.  Then, we adjusted higher, to 30, 50, 100, and 200.  The best result was either 100 or 200 timesteps depending on the run, since there is randomness in the run.  For efficiency, we settled on using 100 timesteps.
Layers and Units per layer: We adjusted Layers from 2, 3, 5 and 9.  We varied the Units per layer from 10, 20, 50, 100, and 200, leaving smaller sizes on the first and last layer.  More layers and / or more Units per layer did not necessarily provide better results.  Too few Layers ad Units, such as 2 layers or 10 Units per layer did produce worse results.  We settled on 3 Layers, being 50, 1000 and 50 Units per layer as the best result while maintaining fairly efficient processing.  With the PyTorch model, we do not specify individual Units per layer. It is faster in processing overall.  We found that 3 layers with 96 Units per layer was most effective for Pytorch.
Learning Rate and Epochs: When adjusting Learning Rate, we tried .01, .001, .0001, .00002, .00001, and .000001.  Each time we brought the learning rate down, the predictions improved, assuming we increased the Epochs to accommodate the slower learning rate.  However, the effects were very small at the slowest rates and Epochs needed to be increased dramatically, leading to very inefficient processing.  We settled on a Learning Rate of .00001 and 70 Epochs as good prediction performance balance.
Batch Size: We tried batch sizes of 12, 24, 28, 32, 48, 64, and 96.  We saw little effect on predictions by increasing the batch size.  However, a very small size produced worse results.  We settled on a Batch Size of 28 as a good prediction performance balance.
Stock Tickers:  We analyzed various stock tickers, including several tech stocks, industrials, and a couple of ETFs. Interestingly, we found that more volatile stocks, such as AAPL (52.91%), AMZN (54.07%), and GOOG (54.07%), on average yielded poorer predictions compared to others. Although these stocks have high trading volumes, their price swings may make them harder to predict accurately. In contrast, stable industrials like Citigroup (C) at 54.07%, Chevron (CVX) at 51.16%, IBM at 53.49%, and AT&T (T) at 55.23% performed slightly better. The increased stability in these stocks may have contributed to more consistent predictions.
The most liquid ETFs, such as QQQ (54.65%), SPY (53.49%), and VTI (55.23%) performed the best overall. The broader market representation and high liquidity of these ETFs appear to support better prediction outcomes, likely because they mitigate the effects of individual stock volatility.  While all of the prediction percentages are very close, we feel it is amazing that all predictions performed better than 50%.




